{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Привет Виктор! Меня зовут Марат, и я буду твоим ревьюером. Спешу сообщить что все ключевые этапы в работе выполнены,  с задачей тебе удалось справиться. По поводу обращения - в IT сфере принято общаться на «ты» :) Но, если привычней на «вы», дай знать. Как ревьюера моя задача помочь тебе в развитии, дав хорошие советы. Я внимательно посмотрю твой код, ознакомлюсь с твоими выводами и оставлю комментарии. Где то могу предложить небольшие исправление в коде, но ненавязчиво. Где потребуются уточнения, я оставлю много наводящих вопросов. Они помогут тебя с поиском верного решения.\n",
    "\n",
    "Все мои комментарии размечены по цветам, для лучшего восприятия. \n",
    "    \n",
    "<div class=\"alert alert-success\">Зеленым цветом и словом «Успех» отмечены особо удачные и элегантные решения, которыми ты можешь гордиться. </div>\n",
    "        \n",
    "<div class=\"alert alert-warning\">Желтым и значком словом «Совет», помечены решения у которых есть альтернативные решения, более оптимальные. Ты можешь найти их сразу и доработать проект, или отложить это на потом, для будущих проектах. Проект будет принят и без их доработки. </div>\n",
    "        \n",
    "<div class=\"alert alert-danger\"> Красным цветом и значком словом «Ошибка» помечу твои решения, на которые стоит обратить внимание прежде всего. После их доработки проект будет принят. </div>\n",
    "        \n",
    "Залог успеха - работа сообща, взаимное уважение и работа в диалоге. Поэтому, помечай свои ответные комментарии на мои реплики заметным цветом или курсивом, так мне будет легче их отслеживать. Пожалуйста, не изменяй и не удаляй мои комментарии. Все это поможет выполнить повторную проверку быстрей.\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "    \n",
    "Для лучшей коммуникации будет лучше если ты будешь оставлять ответные комментарий (cвои комментарии к исправлениям, вопросы), так результат будет лучше.  А чтобы ревьюры их не теряли, лучше их подсвечивать цветом (можешь выбрать свой, а можешь использовать   тот который я предложил ниже). И чтобы не возникло путаницы лучше оставлять указание на номер версии комментария по итерация:  \n",
    "\n",
    "1 итерация\n",
    "\n",
    "<div class=\"alert alert-info\"> <b>Комментарии студентаV1:</b> Привет Марат!.</div>\n",
    "\n",
    "\n",
    "2 итерация\n",
    "\n",
    "<div class=\"alert alert-info\"> <b>Комментарии студентаV2:</b> Исправлено.... </div>\n",
    "    \n",
    "    \n",
    "И лучше подсвечивать свои комментарии цветом, для этого достаточно в ячейку markdown добавить: \n",
    "\n",
    "```html\n",
    "<div class=\"alert alert-info\"> <b>Комментарии студентаV2:</b> Исправлено.... </div>    \n",
    "\n",
    "```    \n",
    "    \n",
    "Хорошая коммуникация залог успеха! )\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заказчик:** \n",
    "Интернет-магазин «Викишоп» \n",
    "\n",
    "\n",
    "**Описание проекта:** \n",
    "заказчик запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Цель проекта:**\n",
    "\n",
    "Обучить модель классифицировать комментарии на позитивные и негативные. Соответственно, в ходе проекта будет решена задача бинарной классификации.\n",
    "\n",
    "Необходимо, чтобы метрика качества *F1* имела значение не меньше 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ход исследования**\n",
    "- **Подготовка данных**: загрузка и изучение общей информации о предоставленном датасете. Корректировка типов данных, дубликатов и пропусков. Токенизация, лемматизация, векторизация текстов. Разбивка данных на выборки перед обучением моделей.\n",
    "\n",
    "- **Обучение и оценка моделей**: обучение моделей для задачи классификации. Оценка качества, выбор лучшей модели  и её проверка на тестовой выборке.\n",
    "\n",
    "- **Общий вывод** и подведение итогов по проделанным работам, рекомендации заказчику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade scikit-learn -q\n",
    "!pip install wordcloud==1.8.2.2 -q\n",
    "!pip install vaderSentiment -q\n",
    "!pip install --upgrade Pillow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка\n",
    "<a href=\"#Содержание\">Назад к содержанию</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала загрузим данные. Применим библиотеку os, чтобы убедиться в корректности пути, по которому находится датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(159292, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pth = '/datasets/toxic_comments.csv'\n",
    "if os.path.exists(pth):\n",
    "    toxic_comments = pd.read_csv(pth)\n",
    "    display(toxic_comments.head(), toxic_comments.shape)\n",
    "else:\n",
    "    print('Something is wrong')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего в датасете 3 признака и 159292 наблюдения. Помимо текстов и таргета присутствует лишний признак «Unnamed: 0». Он дублирует индекс датасета и не имеет значения для дальнейшего обучения, удалим его."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "Если не знаешь - чтобы не было столбца  `Unnamed: 0` при чтении файла можно так:\n",
    "\n",
    "\n",
    "    pd.read_csv(..., index_col=0)\n",
    "\n",
    "    \n",
    "(`Unnamed: 0` появляется при не совсем корректном сохранении файла)    \n",
    "\n",
    "\n",
    "Он не совсем дублирует. Unnamed: 0 это \"след\" старых индексов. Если ты уберёшь первые 10 примеров и своего датасета, сохранишь его, а потом откроешь,  то появится столбец Unnamed: 0 начиная с цифры 9, и появится новый индексы начиная с нуля \n",
    "\n",
    "\n",
    "Но это мелочь,  даже не нужно ничего исправлять. Просто знай, чтобы увидев такое в чужом коде не удивляться что бы это могло означать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарии студентаV1:</b> Привет Марат! Понял, буду знать</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "Привет Виктор!\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_comments = toxic_comments.drop('Unnamed: 0', axis=1)\n",
    "toxic_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим данные на наличие пропусков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_comments.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски отсутствуют, проверим наличие дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_comments.duplicated(subset='text').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одинаковые тексты отсутствуют. Убедимся, что таргет принимает только 2 значения — 1 и 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_comments['toxic'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся в корректности типов данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "toxic_comments.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Типы данных распределены корректно. Теперь проанализируем распределение меток класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Частота значений для признака: toxic'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "sns.countplot(data=toxic_comments, x='toxic')\n",
    "plt.title('Столбчатая диаграмма для toxic', fontweight='bold')\n",
    "plt.ylabel('Количество наблюдений', fontsize=14)\n",
    "plt.xlabel('toxic', fontsize=14)\n",
    "plt.xticks(rotation=30)\n",
    "display('Частота значений для признака: toxic',\n",
    "        toxic_comments['toxic'].value_counts()\n",
    "       ) \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Негативных текстов в разы меньше (в 8.84 раза). При разбиении данных на выборки необходимо будет учесть дисбаланс классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    " \n",
    "Плюс за   проверку на сбалансированность \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "- можно также посчитать количество слов в предложений,  длину слов в твите, опять же в разбивке по Таргету.  Если будут какие-то сильные отличия, возможно из-за этого стоит сгенерировать дополнительные признаки для наших моделей. Или например можно использовать библиотеку SentimentIntensityAnalyzer для оценки сантиментов, и посмотреть насколько хорошо ее оценки корелирует с нашими таргетами\n",
    "   \n",
    "   \n",
    "- когда мы работаем с текстами, describe итп описательные статистике не использовать, но можно провести частотный анализ текста.  Предлагаю для этого использовать [облако слов](https://habr.com/ru/post/517410/) - чтобы получить общее представление о тематике и о наиболее часто встречаемых словах в токсичных и нетоксичных твитах (в облаке уже автоматически будут убраны стоп слова). Кроме того графики, рисунки делают проект визуально интересней\n",
    "   \n",
    "   \n",
    "В тренажере облако импортируем так\n",
    "\n",
    "    !pip install wordcloud \n",
    "\n",
    "\n",
    "или\n",
    "\n",
    "    !pip install wordcloud==1.8.2.2  \n",
    "\n",
    "\n",
    "И возможно дополнительно надо будет сделать\n",
    "\n",
    "\n",
    "\n",
    "    !pip install --upgrade Pillow  (попробуй версию 9.5.0)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарии студентаV1:</b> \n",
    "    \n",
    "Ниже применил SentimentIntensityAnalyzer, облако слов почему-то никак не хочет работать. Пробовал с таким кодом:\n",
    "    \n",
    "    all_lemmas = [lemma for sublist in toxic_comments['text'] for lemma in sublist]\n",
    "    full_text = ' '.join(all_lemmas)\n",
    "\n",
    "    wordcloud = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color='white'\n",
    "    ).generate(full_text)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')  \n",
    "    plt.show()\n",
    "\n",
    "Выдаёт ошибку: «ValueError: Only supported for TrueType fonts». \n",
    "    \n",
    "Пробовал по твоему совету !pip install --upgrade Pillow, не помогло. Также не помогло указывать вручную параметр облака font_path='/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', хотя шрифт относится к TrueType\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Совет 🤔:\n",
    "\n",
    "\n",
    " К сожалению кроме выше озвученных вариантов как в побороть эту ошибку не знаю. Примерно у 20% студентов не получается построить облако.  Причём в один день может быть построено в другой нет.  Видимо какие-то проблемы с версиями библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружены предсказанные классы из файла.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEJCAYAAABohnsfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAArJUlEQVR4nO3dedwVZf3/8df7BlFSDHMBBVxKXHBJS1FzyUwUzSXLzLXIBTXJvvVVcwv3LJfMhUQit8zdn4lK+FVLzYWEtFTcQjJFBFxANDQUP78/5jo4HO5zzzlw7vvc3Pf7yWMe3DPXLJ+ZOXM+c12zHEUEZmZm1WhqdABmZrb0cNIwM7OqOWmYmVnVnDTMzKxqThpmZlY1Jw0zM6uak4aZmVWtMGlIelnSzrn+PpKmSDqvdUMzM7P2pqaahqRVgfuAP0bECa0TkpmZtVsR0WIHvAzsDPQEngSuAZQrXxb4FTAtdb8Clk1lOwJTgZOBN9O8DspNezUwErgXeBd4EFgrV75BKnsbeAHYryy204EPgfeA/wABdE1l2wF/T/N9D/gY2DG33LNz81k32xQLzfe6XP+v07zXTf29gf8DZqd5fwicXmH7nZ6m3Sc37Ptp2OG5YYcCzwGzgHtK2wFYJa37vvltmv5uAm4DflW2zKnA+ym2eaV1AY4Hbisb9xLg4pb2ffp7BWAG8HCufKPc/pmR9vM2abml7TIv178mMKRsHiekbbFzbnvlt33XVL52lfvugfx2zQ0/G7g6/b12mucdufKV0jbLx5bf52um8usqbKsF+yX171e+j1v47Ja68vVckmPjcGB+2bzXzZUfQfZ5exd4FvhCM/t8IPA6MDDX/xjZ5/514DKgWypbHngamAO8BYzik2Ox4nTl27mFfdU1V34d6Xgr3+4Fn5sANs+Ncx4tf/YWOu6bWcYDZJ/v1XLDbi773CwLXAC8QnaMjAS6p7LZad98ULavDipfb7LvjEnAyqn/e7n9NwU4suyzGOSOa2BAGnZdc9s17aMgd2xV6qqtaawA/DHtiEMjLSU5Bdga2Az4fFr4qbny3mRffH2A7wKjJK2fKz8IOCuN83fg9wCSlic7KK4HVgP2B34taUBu2ibgxohYgewLLO8C4HZgxVQ+rcp1XYik9YDdygb/D9lOXj3N+6aC2TxPdhCXDAH+mVvG3mRfuN8AVgX+AtwAEBFvAl8DfinpS2XzvRAQ8OPysIHBKbaf5YZfBwyW1DMttyvZdr22IH7IEs6HuZh7kNU6xwFrkH153x8Rj0XECmnZvwfOK/VHxCsLBSl9BjiW7OBphHUkrZ7+PgT4VwvjnkX2ZVhI0jJp/NcLRr0pt616NlO+JMeGgIdy88/H9y2yL8jvACsCe5Wvm6QNyY6fgyPi8TR4PvCjFM82wFfJvswA/pvi6EmW0Lbhk+Ompena0oLjMO2jPcm+yBdR4bhvzktk32tIWgVYr6z852nYZmTHSB9gOEBE9Ez75ijgsdxx8vuyWPYHjgN2jYjSfpoJ7EG2/74HXCTpC7nJ3gB2k7Rs6j+cLMlUcj7wWhXrW3XSuJwsA/YFti0rOwg4MyJmRsQbwBlkB2DeTyPivxHxIHA32VlYyd0R8VBE/JcsAW0jqR/ZBnk5Iq6KiI8i4kmys+pv5abtRpbpK+lCdvAsiZ+RHbjlmqh++/0N6C2pb9qxM1g4iR0FnBsRz0XER2mZm0laCyAiJpN9MMcA/QEkHUuWTA6KiI/LltedZrZLRLwOPMQn23Aw8GZE/K2l4CX1Bg4DfpkbvAcwPSIujIgPIuLdiPhr0YYoczJwJfBOjdPVy7VkCRyy7XtNcyNJ2pTsy67Z8mYcCfwVeHEJ41uSY6PZz0ByOFkynxCZyRHx71z5WmQ16VMj4v7SwIj4W0SMT8t8GbgC+HIq+ygiJqXPoshq/i8WTdfGxgCDJHUnSxj3kZ3lN6fScV/uWj75vvsO8LtSgSQBQ4EfRcTbEfFumu/+NcQ8GPgtsFtETC0NjIi7I+KltP8eJNtf2+emmweMBb4hqRtZAvxDcwuQtAfZPruvmoCq/dJ7nmwjnwCMThu9ZA0g/4H7dxpWMisi/tNC+aulPyLiPbLq9hpkH9ytJM0udWQJqndu2s+QNec05wdkZ1AfpGnXqDBeRZK2BtZn0S+LC4G5wLtp3vtR7CqyM4LDgdFlZWsBF+fW822yndgnN84gsqaDX5HVRn4A9CA7e8nHvCzZ2d4bFeK4Bjg4/X0wuQ95C04DLk1xlfQjO8taLCkh7kd2hlNuv9y2eLOZ8uNy5U80U35JKn9d0pWSlqsQxu+AgyRtxSfNB835BfBTcjWtSlIN7IQ0/pJakmOjN5U/A0X77lKyJs5B+YGS1pN0l6TpkuaQfQGuUjbObLLtOBWYXu10wBO5dTmumZjezJWXH29rpLJZkp6UtGuF9fqQLHHsS3YSVH4cltah0nHfnDeAFyVtT5Y88rX2VYFPAX/LxT4uDa/WaLLjfqEkK2k3SeMlvZ3muzuLbtPRZOv59bTc5k4iugDnkn1mq1Jt0jgnnU3+huyDnM/A08g+xCVrsvBZ9EqpOl2pvF/pD0krkCWCaWk5D6YqXKlbISKOzk27HhXO5iJiAlmCOiUierJ4zVPnASdFxPyyeb9B1oT0xzTvm6uY13XAgcBXyGpbea+StUnm17V7RDwKkJodvkd2tnA2WXV/D+Ak4Ip0RlOyGVk7Z6Wmlj8Am0raOM3j9xXGK1kP2BW4uJmYP1swbUvOIjvbfbeZsptL24FFDwSAC3LlX2im/NhUthHwRT6pTZR7C3iG7My32S8QYCdgZarbx5A1491cdua+uJbk2Ngc+EeF+b4KfK6F5Z5P1oQ0UNJeueGXk51A9o+IFclqigvV5NN2/wzZicvJ1U5Hdk2ltE8vaCamVXLl5ftiWm65l9Lyl/1osi/IlSOi0vZp9rgvmOelwOT03VDyJtl1sI1y++nT5c2FBQ4Avg2cI6kvLDgxvI1sO/VK6z6WRffFM2RJ61Qqf76/C7wQEeOrDWhxntM4AhgqaWDqvwE4VdKqqU1vONkXZN4ZkrqlbLwHcEuubHdJ26Uq1FnA+Ih4FbgLWE/SIZKWSd2WkjZUZm9gC7JrLYuQtB9ZgrpoMdYRsi+LjyPirmbmvTbwE2pol42I2WS1jQtTE1TeSOAkSRul+X86tTuXqrhXkDUVvEF2QfHtiHghIq4ma0s+Mo3bRFYDuaXSBz4iPgBuJWsPf7z8OkMzTiVrfiyvxt8FrC7pfyQtK6lHOmOvxrrAVmm9WtNcsu3T0uf8IrIbPMZVKD8dOCFioet4lfQgS+7n1BBjS2o+NgAkbQLswMLHWd5ostraF9OxtG6pKTT5S0TMJTtL/bXSNbC0fnOA9yRtACxIUun4L10f6gosQ/aF2eJ09ZT20Wxa2N8R8TzZvj63wigVj/sW/B9ZjXeh75rUVPcbsusNq8GCRxYq1YSa85f05X8J2c0FkDXLL0tWy/lI0m7ALhWm/xlwX0RMqlB+CtnJZ9VqThoRMYUsMVyVPsxnAxOBp8junngiDSuZTtaENI3srPaotONKridr/nib7Kzw4LScd8k2xP5p2ulkzQTLkrXznU3Wnv8qZSStRLYDj2jmC7rkWElTJU0lqzUg6bFc+epUrrJdAfy81rPJiDgvIhbJ+BFxO9m63Ziq78/wyUW4w8juariywmyPAk5Xdt1hJFkzxcGS3pP0HtlZ3bclHZSb5hpgE6prmnqTZi6Up/0ziKzZcjrZhf2vVDE/gF5kSbCwuWcxnZf26xRgMlmyblZE/DUivtfCWeWTEfFAlctdEbgkIio1mdaq5mND0ppkSbA78EzucwBwZ5r+FrLEdj1ZrfQPZGfpC0lt5X/gky/D48hqy++SfRnmbwDpCzyYljWJrKZ7fhXT1UPv3LF8NtkxU1FEHB8Rd1Qobum4rzS/jyPi0FLLQJmfkH0Gx6dj+z6ypq9a/ZzsJO27af8fS1bjmkW2bcdUiO2uiCi/USbvroj4Zwvli1B1J1CLR9KOZLd49a1QfjXZ7XKnNlfe1iS9HBFrNzqOxZW259XlX3KSDia7te7q1L8mWXNB74iY08ZhWhUW99hIteCrI2LHZsrui4idF5nIrAZdGx1AO/NwowNYQm+TNceU+w9pX6cmrB+T3arshNHxfETlC+CVhptVzUkjJyIOLh6r/apUDU3NX6X7+2eQ3SAwuA1DszaSbsv8VoWyA9o4nE5N0pVk13BnRsTGzZSL7AaT3cmuvw2JiObuBmxXWrV5ysyss5K0A9nzbddWSBq7k924sjvZjSEXR0S1N5M0jN9ya2bWCiLiIRZ+tqnc3mQJJdItrz1zd6C1W26eaiPdNx/mKt1SZNaEyxodgtVoua5L/PaHmo7TD/4+4kiyJ75LRkXEqErjN6MPuQc4yR6I7EPx62cayknDzGwxpARRS5LoEJw0zMxK1KYt9q+Re+qf7FmXql4a2Ei+pmFmVtLUpfpuyY0BvpOeyt8aeCeyl4q2a65pmJmVaIkvi+RmpRvIfttilfS0+mlkr1chIkaSvS9qd7InxueSvYKm3XPSMDMrqWPzVNFzMeldWcfUbYFtxEnDzKykjjWNjspJw8yspG0vhC+VnDTMzEpc0yjkpGFmVlKfu6I6NCcNM7MSN08VctIwMytx81QhJw0zsxLXNAo5aZiZlThpFHLSMDMraXLzVBEnDTOzEt89VchJw8ysxM1ThZw0zMxKfPdUIScNM7MS1zQKOWmYmZW4plHIScPMrMQXwgs5aZiZlbh5qpCThplZiZunCjlpmJmVuKZRyEnDzKzESaOQt5CZWYlUfVc4Kw2W9IKkyZJObKZ8LUn3S3pK0gOS+rbKOtWZk4aZWUlTl+q7FkjqAowAdgMGAAdIGlA22gXAtRGxKXAmcG4rrFHdOWmYmZWoqfquZQOByRExJSLmATcCe5eNMwD4U/r7z82Ut0tOGmZmJTU0T0kaKmlirhuam1Mf4NVc/9Q0LO8fwDfS3/sAPSSt3HorVx++EG5mlqiGW24jYhQwagkWdxxwmaQhwEPAa8D8JZhfm3DSMDNLakkaBV4D+uX6+6ZhC0TENFJNQ9IKwDcjYna9Amgtbp4yMytRDV3LJgD9Ja0jqRuwPzBmoUVJq0gLLo6cBFxZn5VoXU4aZmZJU1NT1V1LIuIjYBhwD/AccHNETJJ0pqS90mg7Ai9IehHoBZzTemtWP26eMjNL6tg8RUSMBcaWDRue+/tW4Na6LbCNOGmYmSX1TBodlZOGmVmJc0YhJw0zs8Q1jWJOGmZmSdEFbnPSMDNbwDWNYk4aZmYlzhmFnDTMzBLXNIo5aZiZJU4axZw0zMwSJ41iThpmZomanDSKOGmYmSWuaRRz0jAzS5w0ijlpmJklThrFnDTMzEqcMwo5aZiZJa5pFHPSMDNL/O6pYk4aZmYlrmgUclq1Zo087SD+ff+5TLzl5IrjXHjCvjxzx2k8ftNJbLZB3wXDD9pzK56+YzhP3zGcg/bcqi3CNeCRvzzEXl/blT0GD+K3vxm1SPm1V1/FPnvuzr777MkRh36XadNeW1B29NDD2G7rLRj2/SPbMuR2R1LVXWflpGHN+t2d49n7mBEVy3fdbgCfW3NVNt77DIadfQOXnLw/ACut+ClOGbobOxxyAdsffD6nDN2Nnj26t1XYndb8+fP52Tln8uuRo7l9zN2MG3sXL02evNA4G2y4IdfffBu33n4ng3bZlYsuPH9B2ZBDD+fsc89r67DbnXomDUmDJb0gabKkE5spX1PSnyU9KekpSbu3ykrVmZNGlSStI2m5XH93SWs3MKRW9cgTL/H2O3Mrlu/x5U25/q7HAXj86Zf5dI/u9F5lRQZ9aUPuH/88s+bMZfa773P/+OfZZdsBbRV2p/XM00/Rr99a9O3Xj2W6dWPw7l/jgT/fv9A4A7famu7dswS+yec3Y+b06QvKttp6G5Zffvk2jbk9qlfSkNQFGAHsBgwADpBUfiCcCtwcEZsD+wO/boVVqjsnjerdAnyc65+fhnVKa6zWk6nTZy3of23GbNZYrSdrrNqTqTNyw2fOZo1VezYgws5l5owZ9F6994L+1Xr1YsaMGRXHv/22W9l2+x3aIrSlippUdVdgIDA5IqZExDzgRmDvsnECWDH9/WlgWl1XppU4aVSva9r5AKS/u7U0gaShkiZKmvjRm5NaPUCzatx15x08O+kZhhx6eKNDaXfq2DzVB3g11z81Dcs7HThY0lRgLPCDeq1Ha3LSqN4bkvYq9UjaG3izpQkiYlREbBERW3RdZaNWD7AtTZs5m769V1rQ36dXT6bNnM20N2bTt1du+Go9mfbG7AZE2Lms1qsX01//pLlp5owZ9OrVa5Hxxj/2KKNHjeTiyy6nW7cWz3k6pVqSRv6kMHVDa1zcAcDVEdEX2B34naR2/53c7gNsR44CTpb0iqRXgZ8AnfZWk7sffJoD9xgIwMBN1mbOe+8z/c053Pvoc+y8zQb07NGdnj26s/M2G3Dvo881ONqOb6ONN+GVV15m6tRX+XDePMaNvZsvf2WnhcZ57rlnOeuM4Vx82eWsvPLKDYq0fZOq7/InhanL37L2GtAv1983Dcs7DLgZICIeA5YDVmnN9asHP6dRpYh4Cdha0gqp/70Gh9Sqrjl3CNt/sT+r9FyByePO4qyRY1mmaxcARt/6MOMensSu223EpDGnMfeDDzny9OsAmDVnLuf+ZhwPX3cCAD8bNY5ZcypfULf66Nq1KyedMpyjhx7Oxx/P5+v7fJN11+3PiEsvZqONNmbHnb7KRRecx9y5czn+Rz8EoPfqq3PJiJEADDnkQF7+1xTmzp3LoJ124PQzz2Hb7bZv5Co1RB1vpZ0A9Je0Dlmy2B84sGycV4CvAldL2pAsabxRrwBaiyKi0TG0a5IOjojrJP24ufKI+GU18+m++TBv6KXIrAmXNToEq9FyXZf80bz1ThhX9XH64nmDW1xeuoX2V0AX4MqIOEfSmcDEiBiT7qb6DbAC2UXxEyLi/xY7+Dbimkax0n2IPRoahZm1uqY6/ghTRIwlu8CdHzY89/ezwLZ1W2AbcdIoEBFXpP/PKC+T5CuJZh1IPZNGR+UL4VWS9ED+YT5JW5K1W5pZB1HLhfDOyjWN6p0LjJN0Cdn91rsB32tsSGZWT535nVLVctKoUkTcI+ko4F6y5zM2j4jpBZOZ2VLEOaOYk0aVJP0U2A/YAdgUeEDS/0bE3Y2NzMzqxTWNYk4a1VsZGBgR7wOPSRoHjAacNMw6CF8IL+akUaWI+B9JvSR9NQ16PCIGNTQoM6sr1zSK+e6pKkn6FvA48C2yZqq/Stq3sVGZWT357qlirmlU71Rgy4iYCSBpVeA+4NaGRmVmdeOaRjEnjeo1lRJG8hauqZl1KM4ZxZw0qvdHSfcAN6T+b1P2igAzW7r5QngxJ43qBXAFsF3qHwVs3bhwzKze3DxVzEmjeoMi4ifA/ysNkHQG2e9qmFkH4JxRzEmjgKSjge8Dn5X0VK6oB/BIY6Iys9bgmkYxJ41i1wN/JHv31Im54e9GxNuNCcnMWoNzRjEnjQIR8Q7wDtnv+ZpZB+aaRjEnDTOzxHdPFXPSMDNLXNMo5qRhZpY4ZxTzE81mZomkqrsq5jVY0guSJks6sZnyiyT9PXUvSprdGutUb65pmJkl9appSOoCjAAGAVOBCZLGRMSzpXEi4ke58X8AbF6fpbcu1zTMzJKmJlXdFRgITI6IKRExD7gR2LuF8Q/gk1cUtWtOGmZmSZNUdSdpqKSJuW5oblZ9gFdz/VPTsEVIWgtYB/hT661Z/bh5yswsqaV5KiJGkb2DbkntD9waEfPrMK9W56RhZpbU8Zbb14B+uf6+aVhz9geOqdeCW5ubp8zMkiZV3xWYAPSXtI6kbmSJYUz5SJI2AFYCHqv3urQW1zTMzJJ61TQi4iNJw4B7gC7AlRExSdKZwMSIKCWQ/YEbIyLqsuA24KRhZpY01fHpvogYS9kPtUXE8LL+0+u2wDbipGFmlvjVU8WcNMzMEr97qpiThplZ4pxRzEnDzCyp5zWNjspJw8wscc4o5qRhZpb4R5iKOWmYmSVunirmpGFmljhlFHPSMDNLfMttMScNM7PElzSKOWmYmSW+EF7MScPMLHHzVDEnDTOzxBWNYk4aZmaJaxrFnDTMzBKnjGJOGmZmiR/uK+akYWaW+O6pYk4aZmaJKxrFnDTMzBI3TxVranQAZmbthVR9VzwvDZb0gqTJkk6sMM5+kp6VNEnS9fVen9bgmkYbmTXhskaHYDVYacthjQ7BavT+k0t+jNXrlltJXYARwCBgKjBB0piIeDY3Tn/gJGDbiJglabW6LLyVuaZhZpY01dAVGAhMjogpETEPuBHYu2ycI4ARETELICJm1mUlWpmThplZ0qVJVXeShkqamOuG5mbVB3g11z81DctbD1hP0iOSxksa3NrrVw9unjIzS2q54zYiRgGjlmBxXYH+wI5AX+AhSZtExOwlmGerc03DzCyRVHVX4DWgX66/bxqWNxUYExEfRsS/gBfJkki75qRhZpY0qfquwASgv6R1JHUD9gfGlI3zB7JaBpJWIWuumlLP9WkNbp4yM0vq9ZhGRHwkaRhwD9AFuDIiJkk6E5gYEWNS2S6SngXmA8dHxFv1iaD1OGmYmSVd6/hwX0SMBcaWDRue+zuAH6duqeGkYWaW+IHwYk4aZmaJXyNSzEnDzCxxzijmpGFmlvjN6MWcNMzMEjdPFXPSMDNLuvjJtUJOGmZmifwr4YWcNMzMEl/TKOakYWaWOGkUc9IwM0vq9SNMHZmThplZ4ppGMScNM7Oki7NGIScNM7PEOaOYk4aZWeJLGsWcNMzMkiY/p1HIScPMLHFNo5iThplZ0tUXNQo5aZiZJa5pFPPruczMkiap6q6IpMGSXpA0WdKJzZQPkfSGpL+n7vBWWak6c03DzCypV01DUhdgBDAImApMkDQmIp4tG/WmiBhWn6W2Ddc0zMySphq6AgOByRExJSLmATcCe7dK0G3MScPMLJFUdVegD/Bqrn9qGlbum5KeknSrpH71Wo/W5KRhZpZ0karuJA2VNDHXDa1xcXcCa0fEpsC9wDX1X6P68zUNM7OklksaETEKGFWh+DUgX3Pom4blp38r1zsaOK+GxTeMaxpmZolUfVdgAtBf0jqSugH7A2MWXpZWz/XuBTxXz3VpLa5pmJkl9fo9jYj4SNIw4B6gC3BlREySdCYwMSLGAMdK2gv4CHgbGFKXhbcyJw0zs6SeTS8RMRYYWzZseO7vk4CT6rjINuGkYWaWVPPQXmfnpGFmlvjnXos5aZiZJb4zqJiThplZ4ppGMScNM7PEKaOYk4aZWeKKRjEnDTOzpIuzRiEnDTOzRG6gKuSkYWaWuKJRzEnDzCxpck2jkJOGmVnimkYxJw0zs8RJo5iThplZ4runijlpmJklvnuqmJOGmVniikYxv5/LKnrkLw+x19d2ZY/Bg/jtbxb9Vctrr76KffbcnX332ZMjDv0u06Z98muWRw89jO223oJh3z+yLUPu1EaedhD/vv9cJt5ycsVxLjxhX5654zQev+kkNtug74LhB+25FU/fMZyn7xjOQXtu1Rbhtkuq4V9n5aRhzZo/fz4/O+dMfj1yNLePuZtxY+/ipcmTFxpngw035Pqbb+PW2+9k0C67ctGF5y8oG3Lo4Zx97lLxk8cdxu/uHM/ex4yoWL7rdgP43JqrsvHeZzDs7Bu45OT9AVhpxU9xytDd2OGQC9j+4PM5Zehu9OzRva3CbleaVH3XWTlpWLOeefop+vVbi779+rFMt24M3v1rPPDn+xcaZ+BWW9O9e/blssnnN2Pm9OkLyrbaehuWX375No25s3vkiZd4+525Fcv3+PKmXH/X4wA8/vTLfLpHd3qvsiKDvrQh949/nllz5jL73fe5f/zz7LLtgLYKu11pkqruOisnDWvWzBkz6L167wX9q/XqxYwZMyqOf/ttt7Lt9ju0RWi2mNZYrSdTp89a0P/ajNmssVpP1li1J1Nn5IbPnM0aq/ZsQISNpxq6zspJowaSjpHUM9e/kqTvNzCkduGuO+/g2UnPMOTQwxsditkSqWdNQ9JgSS9ImizpxBbG+6akkLRFXVemlThp1OaIiJhd6omIWcARlUaWNFTSREkTm7uQ3J6t1qsX01//pLlp5owZ9OrVa5Hxxj/2KKNHjeTiyy6nW7dubRmi1WjazNn07b3Sgv4+vXoybeZspr0xm769csNX68m0N2Y3IMLGq1dNQ1IXYASwGzAAOEDSIm1+knoAPwT+WqdVaHVOGrXpotxPe6UPRsVvyogYFRFbRMQWhx0xtE0CrJeNNt6EV155malTX+XDefMYN/ZuvvyVnRYa57nnnuWsM4Zz8WWXs/LKKzcoUqvW3Q8+zYF7DARg4CZrM+e995n+5hzuffQ5dt5mA3r26E7PHt3ZeZsNuPfR5xocbYPUr31qIDA5IqZExDzgRmDvZsY7C/gF8EEdom8Tfk6jNuOAmyRdkfqPTMM6nK5du3LSKcM5eujhfPzxfL6+zzdZd93+jLj0YjbaaGN23OmrXHTBecydO5fjf/RDAHqvvjqXjBgJwJBDDuTlf01h7ty5DNppB04/8xy23W77Rq5Sh3fNuUPY/ov9WaXnCkwedxZnjRzLMl27ADD61ocZ9/Akdt1uIyaNOY25H3zIkadfB8CsOXM59zfjePi6EwD42ahxzJpT+YJ6R1bLrbSShgL5s8FREVFqUugDvJormwosdC+zpC8A/SLibknHL17EbU8R0egYlhqSmsgSxVfToHuB0RExv2jaDz7CG3opstKWwxodgtXo/ScvW+Lr0xOmvFP1cbrlZz9dcXmS9gUGR8Thqf8QYKuIGJb6m4A/AUMi4mVJDwDHRcTEJYm/LbimUYOI+Bi4PHVm1tHU77ao14B+uf6+aVhJD2Bj4IHU4t0bGCNpr/aeOJw0qiDp5ojYT9LTsGiNISI2bUBYZlZndXzSewLQX9I6ZMlif+DAUmFEvAOssmC5rml0OD9M/+/R0CjMrFXV65m9iPhI0jDgHqALcGVETJJ0JjAxIsbUZ0ltz0mjChHxevpz+Yh4Nl8maUfg320dk5nVXz0f2ouIscDYsmHDK4y7Yx0X3ap8y21tbpb0E2W6S7oUOLfRQZlZnfiR8EJOGrXZiuzi1qNkbZbTgG0bGpGZ1Y3fPVXMzVO1+RB4H+gOLAf8K91RZWYdQOdNBdVzTaM2E8iSxpbA9mSvBrilsSGZWd24eaqQaxq1OSx3S9zrwN7poR0z6wA6848rVctJozb/kHQsUHoH+APAFZVHN7OlSSe+VFE1J43aXA4sA/w69R+S/q74plszW3o4aRRz0qjNlhHx+Vz/nyT9o2HRmFlduXmqmC+E12a+pM+VeiR9Fih8WaGZLR2k6rvOyjWN2hwP/FnSFLL7J9YCDm1sSGZWL504F1TNSaM2DwP9gfVT/wsNjMXM6s1Zo5Cbp2rzWET8NyKeSt1/gccaHZSZ1Ydq+NdZuaZRBUm9yX6Jq7ukzfnkfGRF4FMNC8zM6qqp8+aCqjlpVGdXYAjZD6lcyCdJYw5wcoNiMrN6c9Io5KRRhYi4BrhG0jcj4rZK40n6bhrXzJZCnbnZqVq+plGDlhJG8sOCcjNrx3zLbTHXNOqrE3+UzJZ+PoCLOWnU1yK/H25mSxFnjUJunqovf+TMlmL1/BEmSYMlvSBpsqQTmyk/StLTkv4u6WFJA1plperMSaO+Hml0AGa2+Or1cxqSugAjgN2AAWS/vVOeFK6PiE0iYjPgPOCXdVqNVuXmqSpI+nFL5RHxy/T/sLaJyMxaRf3aCgYCkyNiCoCkG4G9gWdLI0TEnNz4y7OUNG87aVSnR/p/fbJf7RuT+vcEHm9IRGZWd3W85bYP8Gqufyqw1SLLk44Bfgx0A3aq18Jbk5NGFSLiDABJDwFfiIh3U//pwN0NDM3M6qiWW2klDQWG5gaNiohRtSwvIkYAIyQdCJwKfLeW6RvBSaM2vYB5uf55aZiZdQC1vEYkJYhKSeI1oF+uv28aVsmNZD/y1u45adTmWuBxSben/q8DfgLcrMOoW/PUBKC/pHXIksX+wIELLUnqHxH/TL1fA/7JUsBJowYRcY6kPwLbp0Hfi4gnGxmTmdVPvZ70joiPJA0D7gG6AFdGxCRJZwITI2IMMEzSzsCHwCyWgqYpcNJYHJ8C5kTEVZJWlbRORPyr0UGZ2ZKr54NWETEWGFs2bHju76XytUNOGjWQdBqwBdldVFcBywDXAds2Mi4zq4/O/E6pajlp1GYfYHPgCYCImCapR8uTmNnSwm+5LeakUZt5ERGSAkDS8o0OyMzqxzWNYn6NSG1ulnQF0FPSEcB9wOgGx2RmdeJXoxdzTaMGEXGBpEFkv9i3PjA8Iu5tcFhmVidunirmpFEDSb+IiJ8A9zYzzMyWds4Zhdw8VZtBzQzbrc2jMLNWUa+33HZkrmlUQdLRwPeBz0l6KlfUA3i0MVGZWb115msV1XLSqM71wB+Bc4H8j6m8GxFvNyYkM6u3an5cqbNz81QVIuKdiHgZuBh4OyL+HRH/Bj6StMjrjs3MOionjdpcDryX63+PpeTNlGZWzLfcFnPzVG0UEQt+XSsiPpbkbWjWQfiW22KuadRmiqRjJS2Tuh8CUxodlJnVh2saxZw0anMU8CWy9+OXfr5xaItTmNlSw0mjmJtWahARM8l+TMXMOiA3TxVz0qiCpBMi4jxJlwJRXh4RxzYgLDOrs85cg6iWk0Z1nkv/T2xoFGbWqpwzijlpVCEi7kz/+/fAzToyZ41CThpVkHQnzTRLlUTEXm0Yjpm1El/TKKbcYwdWgaQvpz+/AfQm+4lXgAOAGRHxo4YE1g5IGhoRoxodh1XP+8yWhJNGDSRNjIgtioZ1Jp19/ZdG3me2JPycRm2Wl/TZUo+kdQD/5KuZdRq+plGbHwEPSJpCdslsLeDIxoZkZtZ2nDRqEBHjJPUHNkiDno+I/zYypnbAbeNLH+8zW2y+plEDSZ8CfgysFRFHpASyfkTc1eDQzMzahK9p1OYqYB6wTep/DTi7ceGYmbUtJ43afC4izgM+BIiIufhxIDPrRJw0ajNPUnfSg36SPgd0qGsaknpK+v5iTnuUpO/UOyYzaz+cNGpzGjAO6Cfp98D9wAmNDanuegKLlTQiYmREXFvfcKxE0o6S7kp/7yXpxBbGXazkL+l0Sce1UD5E0hq1zjdNu4akWxdnWms/nDSqJKkJWInsqfAhwA3AFhHxQAPDag0/Bz4n6e+Szk/dM5KelvRtAEkXSxqe/t5V0kOSmvJfOJLWlXSfpH9IeiLVyqwZkrrUOk1EjImIn7cwSk8WM/kXGAIsVtKIiGkRsW99w7G25qRRpYj4GDghIt6KiLsj4q6IeLPRcbWCE4GXImIzYDywGfB5YGfgfEmrAycB35b0FeAS4Htp++T9HhgREZ8n++Gq19sm/PZF0tqSnpf0e0nPSbpV0qckvSzpF5KeAL4laRdJj6UEe4ukFdL0g9P0T5CdsJTmO0TSZenvXpJuTwn6H5K+RFnyT+MdL2mCpKcknZGb1ymSXpT0MLB+C+uyL7AF8Ps03+6SvirpyXRScaWkZSVtmZaxnKTlJU2StHHaFs+keXWRdEE6IXlK0g/qvvGtVThp1OY+ScdJ6ifpM6Wu0UG1ou2AGyJifkTMAB4Etkw3ABwB3AtcFhEv5SeS1APoExG3A0TEB2mazmp94NcRsSEwh09qAG9FxBeA+4BTgZ1T/0Tgx5KWA34D7Al8key9Z825BHgwJegvAJPIJf+IOF7SLkB/YCDZicAXJe0g6YtkPyy2GbA7sGWllYiIW1NsB6WTigCuBr4dEZuQPfd1dERMAMaQ3Vl4HnBdRDxTNruhwNrAZhGxKdlJhi0F/HBfbb5NdqCUV/s/28y4Hd0mwFssZlNFJ/NqRDyS/r4OKP1o103p/62BAcAjyn4FqBvwGNlDpP+KiH8CSLqO5n9eeCfgOwARMR94R9JKZePskronU/8KZEmkB3B7KalLGlPDeq2f4nsx9V8DHAP8CjgTmAB8kFvfvJ2BkRHxUYr77RqWaw3kmkZtBgAjgH8AfwcuBTZqZECt4F2yLxKAv5A1Q3WRtCqwA/C4pLWA/wU2B3aTtFV+BhHxLjBV0tcBUpPFp9pqBdqh8idoS/3/Sf8LuDfVCjaLiAERcVidYxBwbm4Z60bEb+u8jLyVyRJTD2C5VlyOtTEnjdpcA2xI1hxwKVkS6VA/zBQRb5Gd8T5D9hDjU2RJ8k9kd4rNAH4LHBcR04DDgNGpKSXvEOBYSU8Bj1K5aaUzWFNS6YHQA4GHy8rHA9tKWhcgXQdYD3geWDt3E8EBFeZ/P3B0mraLpE+zcPIHuAc4NHetpI+k1YCHgK+n6xM9yJrCWpKf7wspvnVT/yFkTZgAVwA/JWt2+kUz87kXOFJS1xRPR27m7VDcPFWbjSNiQK7/z5KebVg0rSQiDiwbdHxZ/865cf9G1lQFcHpu+D/Jmk0s+3I9RtKVwLPA5cCCC78R8YakIcANkpZNg0+NiBclDQXuljSXrObXg0X9EBgl6TBgPtl1hccklZL/H9N1jQ2Bx1IT2HvAwRHxhKSbyE4MZpI1KbXkamCkpPfJTiq+B9ySvvwnpLLvAB9GxPXpzrBHJe0ETMnNZzSwHvCUpA/Jrt1cVrBsawf87qkapDblyyJifOrfCjgmIvxAmzVL0trAXRGxcaNjMasH1zRq80Wys6ZXUv+awAuSngYi3QViZtZhuaZRg3QBuKKI+HdbxWLWmiSNALYtG3xxRFzViHis/XDSMDOzqvnuKTMzq5qThpmZVc1Jw8zMquakYWZmVfv/2KkYaJUQfVQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "tqdm.pandas()\n",
    "predicted_file = 'predicted_toxic.csv'\n",
    "\n",
    "def get_predicted_class(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    compound = scores['compound']\n",
    "    # compound <= 0 - класс 1 (негативный), > 0 - класс 0 (позитивный)\n",
    "    return 1 if compound <= 0 else 0\n",
    "\n",
    "try:    \n",
    "    predicted_data = pd.read_csv(predicted_file)\n",
    "    toxic_comments['predicted_toxic'] = predicted_data['predicted_toxic']\n",
    "    print(\"Загружены предсказанные классы из файла.\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    toxic_comments['predicted_toxic'] = toxic_comments['text'].progress_apply(get_predicted_class)\n",
    "    toxic_comments[['predicted_toxic']].to_csv(predicted_file, index=False)\n",
    "    print(\"Предсказанные классы рассчитаны и сохранены в файл.\")\n",
    "\n",
    "sns.heatmap(toxic_comments[['toxic', 'predicted_toxic']].corr(), annot=True, fmt='.2f', cmap='Blues', square=True)\n",
    "plt.title('Корреляция между истинными и предсказанными метками')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Между фактическими метками классов и оценками SentimentIntensityAnalyzer корреляция слабая положительная — 0.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "👍\n",
    "\n",
    "\n",
    "(Некоторые пробуют добавить его в качестве признака, но к повышение метрики это не приводит) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проведем токенизацию и лемматизацию текста с помощью функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные загружены из файла: lemmatized_comments.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[explanation, edit, username, hardcore, metall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[match, background, colour, seemingly, stuck, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hey, man, try, edit, war, guy, constantly, re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[real, suggestion, improvement, wonder, sectio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  [explanation, edit, username, hardcore, metall...      0\n",
       "1  [match, background, colour, seemingly, stuck, ...      0\n",
       "2  [hey, man, try, edit, war, guy, constantly, re...      0\n",
       "3  [real, suggestion, improvement, wonder, sectio...      0\n",
       "4                [sir, hero, chance, remember, page]      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "tqdm.pandas()\n",
    "stop_words = set(nlp.Defaults.stop_words)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_tokens = [\n",
    "        token.lemma_.lower() \n",
    "        for token in doc \n",
    "        if token.is_alpha and not token.is_stop\n",
    "    ]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "output_file = 'lemmatized_comments.pkl'\n",
    "\n",
    "try:\n",
    "    toxic_comments = pd.read_pickle(output_file)\n",
    "    print(\"Данные загружены из файла:\", output_file)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    toxic_comments['text'] = toxic_comments['text'].progress_apply(preprocess_text)\n",
    "    toxic_comments.to_pickle(output_file)\n",
    "    print(\"Данные сохранены в файл:\", output_file)\n",
    "\n",
    "toxic_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "\n",
    "\n",
    "- WordNetLemmatizer  рабочий вариант, но у него есть особенности, для корректной работы ему нужно передавать не просто слово, но и POS-тег (Part of Speech, части речи). Набираемся ума-разума [тут](https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/) если не откроется то [тут](https://translated.turbopages.org/proxy_u/en-ru.ru.5ece9195-67a114e7-50ce8fac-74722d776562/https/www.geeksforgeeks.org/python-lemmatization-approaches-with-examples/) или [тут](https://dnmtechs.com/wordnet-lemmatization-and-pos-tagging-in-python-3-programming/).  Обрати внимание на функцию `get_wordnet_pos`. Сразу хочу предупредить, что если делать Лемматизацию правильно, сучетом постегов, то время может занять минут 20-30 (Если больше значит есть проблемы с эффективностью кода). Так что не удивляйся (вообще советую сохранить результаты Лематизации в каком-то файлике, чтобы каждый раз не тратить на это много времени)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Не забываем провести очистку (Убираем цифры знаки препинания...), у нас и так огромное пространство признаков после Vectorize, так зачем его увеличивать для неинформативных значений (Вряд ли цифра имеет какой-то смысл для прогнозирования токсичный - это комментарии или нет) \n",
    " \n",
    " \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- лемматизацию можно было сделать с помощью SpaCy лемматизатором и прямо скажем как инструмент он более удобен и универсален, не нужно заморачиваться с токенизацией и учётом пос тегов\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Чтобы сэкономить время, и убедиться что всё отработало нормально, берёшь парочку предложений, создаёшь dataframe\n",
    "    \n",
    "    \n",
    "    sentence1 = \"The striped bats are hanging on their feet for best\"\n",
    "    sentence2 = \"you should be ashamed of yourself went worked\"\n",
    "    df_my = pd.DataFrame([sentence1, sentence2], columns = ['text'])\n",
    "    print(df_my)\n",
    "\n",
    "\n",
    "    print(df_my['text'].apply(func))\n",
    "    \n",
    "    \n",
    "    \n",
    "И тестируешь не нем, должно получиться \n",
    "    \n",
    "    \n",
    "    \n",
    "    trying  ------> try, went -------> go  \n",
    "\n",
    "\n",
    "(striped в данном контексте - причастие, используемое в функции прилагательного (также в кембриджском словаре помечено как adjective), соответственно, это и есть начальная форма. Так что по идее должно остаться как прежде)\n",
    "\n",
    "Если всё получилось, то можно использовать на всём датасете"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарии студентаV1:</b> \n",
    "    \n",
    "Понял, применил лемматизацию spacy, результат сохранил в отдельный файлик. Обращаюсь к нему с помощью try-except. По поводу очистки от знаков препинания, цифр и прочего: её совершил вот в этой части кода:\n",
    "    \n",
    "    if token.is_alpha and not token.is_stop\n",
    "    \n",
    "С помощью is_alpha оставил только буквы англ алфавита, остальные символы убрал</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Совет 🤔:\n",
    "\n",
    "\n",
    " Извиняюсь, не заметил \n",
    "    \n",
    "    \n",
    "    if token.is_alpha and not token.is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "правильно, не нужно трогать разряженные матрицы\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разобъём данные на тренировочную и тестовые выборки с параметром stratify — чтобы пропорции классов сохранились во всех выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127433, 1) (31859, 1) (127433,) (31859,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    toxic_comments.drop('toxic', axis=1),\n",
    "    toxic_comments['toxic'],\n",
    "    test_size= .2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=toxic_comments['toxic']\n",
    ")\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения моделей далее потребуется провести векторизацию. Сделаем это с помощью TfidfVectorizer. Чтобы не сломать ядро jupiter, не будем преобразовывать эти данные в массив и затем в датафрейм — оставим в виде разреженной матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c203c7c2bcc34a02884338414b162cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127433 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07f8e1e4fd54d28ae5b679bcf83a80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31859 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127433, 129194) (31859, 129194) <class 'scipy.sparse._csr.csr_matrix'> <class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train['text'].progress_apply(lambda tokens: ' '.join(tokens)))\n",
    "X_test = vectorizer.transform(X_test['text'].progress_apply(lambda tokens: ' '.join(tokens)))\n",
    "print(X_train.shape, X_test.shape, type(X_train), type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'> <class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train), type(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Ошибка ❌:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "- по поводу использования TFIDF (как и Scaler, OHE, OE итд): fit мы не делаем на полной выборки. fit всегда делаем на тренировочной выборке. И это легко объяснить, ведь по логике моделирования мы владеем информацией только из тренировочной выборки. Поэтому \"обучаемся\" (fit_transform/fit) на тренировочной, а  затем \"распространяем\" обученный scaler на test/реальные данные на которых делает прогноз. Ну на самом деле лучшая засунуть TfidfVectorizer в pipeline, тогда не будет утечки и на валидационной выборке\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарии студентаV2:</b> \n",
    "    \n",
    "Понял, обучил именно на тренировочной выборке</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод по подготовке данных**\n",
    "\n",
    "- Изначальная размерность датасета — (159292 строк, 3 признака);\n",
    "- Признак «Unnamed: 0» дублирует индекс датасета и не имеет значения для дальнейшего обучения. Он был удалён;\n",
    "- Пропуски и дубликаты в датасете отсутствуют, типы данных назначены корректно;\n",
    "- Проведена токенизация, лемматизация и векторизация текстов;\n",
    "- Проведена разбивка на тренировочную и тестовую выборки (80% и 20% датасета соответственно).\n",
    "- Негативных текстов в разы меньше, чем позитивных (в 8.84 раза). Это говорит о наличии дисбаланса классов;\n",
    "- Между фактическими метками классов и оценками SentimentIntensityAnalyzer корреляция слабая положительная — 0.21."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "- random_state на месте\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "- здорово что используешь stratify    \n",
    "\n",
    "\n",
    "    \n",
    "- плюс за  проверку\n",
    "    \n",
    "    \n",
    "- здорово что подробно комментируешь свои действия\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "<a href=\"#Содержание\">Назад к содержанию</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "👍  использования гиперссылок\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее обучим 3 модели: логистическую регрессию, дерево решений, к-ближайших соседей. Оценим метрику их качества на кроссвалидации с помощью GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Лучшая модель: Pipeline(steps=[('model',\\n                 LogisticRegression(C=2.6777777777777776, penalty='l1',\\n                                    random_state=42, solver='liblinear'))])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Лучшие параметры: {'model': LogisticRegression(penalty='l1', random_state=42, solver='liblinear'), 'model__C': 2.6777777777777776}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Метрика лучшей модели на кросс-валидации: 0.774407209817857'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "    (\n",
    "        'model', DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "    )  \n",
    "]\n",
    ")\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'model': [DecisionTreeClassifier(random_state=RANDOM_STATE)],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__min_samples_split': [2, 4],\n",
    "        'model__min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    {\n",
    "        'model': [KNeighborsClassifier()],\n",
    "        'model__n_neighbors': [3, 5],\n",
    "    },\n",
    "    {\n",
    "       'model': [LogisticRegression(solver='liblinear', penalty='l1', random_state=RANDOM_STATE)],\n",
    "       'model__C': np.linspace(0.1, 3, 10),\n",
    "    }\n",
    "]\n",
    "\n",
    "search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "best_model = search.best_estimator_\n",
    "best_params = search.best_params_\n",
    "best_score = search.best_score_\n",
    "\n",
    "display(F\"Лучшая модель: {best_model}\")\n",
    "display(f\"Лучшие параметры: {best_params}\")\n",
    "display(f\"Метрика лучшей модели на кросс-валидации: {best_score}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшей моделью оказалась LogisticRegression с параметрами penalty='l1', random_state=42, solver='liblinear' C=2.6777777777777776. Далее проверим её качество на тестовой выборке и сравним результат с дамми-классификатором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Метрика f1 для лучшей модели на тестовой выборке: 0.7811'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_preds = search.best_estimator_.predict(X_test)\n",
    "display(f'Метрика f1 для лучшей модели на тестовой выборке: {f1_score(y_test, best_preds):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "    \n",
    "Ошибка:    \n",
    "    \n",
    "    \n",
    "Нет никакого перебора гиперпараметров,  при этом непонятно откуда взялись  max_depth=10  итд - все эти значения мы не подставляем, а находим в ходе перебора  \n",
    "    \n",
    " \n",
    "    \n",
    "Есть два варианта исправить красное:\n",
    "    \n",
    "    \n",
    "1. Сделать перебор гиперпараметров в ручном цикле ориентируясь на метрику на валидационной выборке \n",
    "    \n",
    "    \n",
    "2.  Можно вместо цикла использовать sklearn-ий встроенный функционал GridSearch. В случаи использования GridSearch, не нужно будет заранее делать валидационную выборку, лучшую метрику автоматом сохранят в best_score_, а лучшую модель (переобученная уже на полном наборе данных) будет хранить в best_estimator_, данные обучения положит в cv_restult_. А главное  он сделает несколько разбиений на train / validation выборки (кросс-валидация), тем самым поборется с рандомом, когда на валидации получен хороший результат только изза удачного сплита. \n",
    "\n",
    "А еще лучше использовать связку GridSearchCV + pipeline. \n",
    "\n",
    "[Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), это тема которая сразу затрагивает кроссвалидацию, тюнинг \"векторайз\", подбор гиперпараметров модели и о том что код стоит делать компактным.\n",
    "    \n",
    "    \n",
    "- в TfidfVectorizer(stop_words=stopwords) у тебя по умолчанию ngram_range=(1, 1), тут можно подбирать разное число n- грамм (и другие параметры), максимизируя метрику, но как объединить перебор по ngram_range с обучением моделей, чтобы не делать это по отдельности или с использованием цикла?! pipeline! Готовый [пример для работы с текстами](https://medium.com/@yoni.levine/how-to-grid-search-with-a-pipeline-93147835d916). Всё что нужно там есть, хотя очень лаконично. Можешь погуглить по:\n",
    "\n",
    "\n",
    "    \n",
    "    pipeline nlp gridsearchcv\n",
    "    \n",
    "    \n",
    "- как избежать ошибки подглядывания в будущее, когда мы предварительно работаем с данными (шкалирование, нормализация, TfidfVectorizer итп итд)? pipeline! особенно это важно, когда мы используем кроссвалидацию. Для TfidfVectorizer делаеь .fit (обучаемся) на train, а transform на test, точно также нужно сделать для валидационной выборки. Но GS делает валидационные внутри себя, спрашивается как добраться до них и избежать подглядывания в будущее? Казалось бы никак, но нет! Pipeline! ) \n",
    "    \n",
    "    \n",
    "- pipeline позволяет делать наш код компактней и читабельней, это большой плюс, когда код будет раздуваться   \n",
    "\n",
    "\n",
    "\n",
    "В общем если сделать GS+pieline будет вообще хорошо )  \n",
    "    \n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарии студентаV1:</b> \n",
    "    \n",
    "Применил GridSearchCV, если что обучение будет минут 25-30</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех: \n",
    "\n",
    "- Все верно, логика моделирования не нарушена, тут тестируем только лучшую модель отобранную на валидации, или парочку лучших, если на валидации результаты близки\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "- Если студент получил на тесте f1 выше 0,75, это считается приемлемым результатом.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "Что может помочь добиться лучшего результата (от простого)? \n",
    "\n",
    "\n",
    " \n",
    "- можно поиграться [порогом](https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/). Ещё можешь посмотреть в [туториале](https://scikit-learn.org/stable/modules/classification_threshold.html). Есть несколько вариантов, главное не использовать для подбора порога тестовую выборку, ведь это будет подгонка. Таким образом можно поднять метрику на процент - полтора\n",
    "   \n",
    " \n",
    "\n",
    "    \n",
    "- попробовать другие модели. проект своеобразный выбор между вычислительными ограничениями (много примеров, расчеты могут затянуться) и задачей получить хорошую метрику. С этой точки зрения  интересная [моделька](https://medium.com/geekculture/passive-aggressive-algorithm-for-big-data-models-8cd535ceb2e6) (открывается с помощью VPN) [или](https://datafinder.ru/products/passivno-agressivnyy-klassifikator-v-mashinnom-obuchenii). Она считается очень шустрой     \n",
    "    \n",
    "\n",
    "\n",
    "- использование предбученной модели Берта, выбрав соответствующую модель и используя полученные эмбединги, даже на небольшом тренировочном датасете можно обучить модель, которая на test покажет хорошую метрику. В этом случаи можно сразу получить метрику > 0.95 (при правильно выбранной модели)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "А ещё можешь посмотреть какие слова  является наиболее важным для классификации с точки зрения модели. Получаем список слов    \n",
    "    \n",
    "    \n",
    "    \n",
    "    .get_feature_names_out().tolist()\n",
    "    \n",
    "    \n",
    "    \n",
    "Получаем коэффициенты важности (для логистической регрессии)    \n",
    "    \n",
    "    .coef_.tolist()[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "А потом можно построить такой-то красивый график с помощью     seaborn\n",
    " \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Метрика f1 на модели DummyClassifier: 0.1845'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_сlf = DummyClassifier(strategy = 'constant', constant = 1)\n",
    "dummy_сlf.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy_сlf.predict(X_test)\n",
    "f1_dummy = f1_score(y_test, y_pred_dummy)\n",
    "display(f'Метрика f1 на модели DummyClassifier: {f1_dummy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У логистической регрессии метрика превосходит 0.75 и значительно выше, чем у DummyClassifier — успех!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет: \n",
    "    \n",
    "    \n",
    "Плюс за проверку.  Хотя на мой взгляд на адекватность стоит применять в разрезе метрики accuracy. А метрика f1 и без того \"умная\", поэтому константные модели на ней ничего интересного не покажут\n",
    "    \n",
    "\n",
    "Можешь попробовать посчитать f1    \n",
    "    \n",
    "    model = DummyClassifier(strategy = 'constant', constant = 1)\n",
    "\n",
    "    \n",
    "Так можно дотянуть метрику до 0,18 )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарии студентаV1:</b> \n",
    "    \n",
    "Метрику дотянул)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "👍\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "<a href=\"#Содержание\">Назад к содержанию</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод по подготовке данных**\n",
    "\n",
    "- Изначальная размерность датасета — (159292 строк, 3 признака);\n",
    "- Признак «Unnamed: 0» не имеет значения для дальнейшего обучения. Он был удалён;\n",
    "- Пропуски и дубликаты в датасете отсутствуют, типы данных назначены корректно;\n",
    "- Проведена токенизация, лемматизация и векторизация текстов;\n",
    "- Проведена разбивка на тренировочную и тестовую выборки (80% и 20% датасета соответственно);\n",
    "- Негативных текстов в разы меньше, чем позитивных (в 8.84 раза). Это говорит о наличии дисбаланса классов;\n",
    "- Между фактическими метками классов и оценками SentimentIntensityAnalyzer корреляция слабая положительная — 0.21."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод по обучению моделей**\n",
    "\n",
    "- Обучено 3 модели: логистическая регрессия, дерево решений, к-ближайших соседей. Проведена оценка качества моделей на кроссвалидации;\n",
    "\n",
    "- Лучшей моделью оказалась логистическая регрессия.\n",
    "\n",
    "- f1 score лучшей модели на тесте — 0.7811. Это выше, чем у бейзлайн-модели dummy classifier (f1 score = 0.1845).\n",
    "\n",
    "- Параметры лучшей модели: LogisticRegression(solver='liblinear', penalty='l1', C=2.6777777777777776,  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Рекомендации заказчику**\n",
    "\n",
    "1) Необходимо провести ручной анализ текстов, где модель дала неверный прогноз (ложноположительный или ложноотрицательный). Это поможет увидеть возможные закономерности и общие черты среди неверно классифицированных комментариев.\n",
    "\n",
    "2) Расширить набор данных для обучения. Дополнительные примеры токсичных и нетоксичных комментариев могут повысить точность классификатора.\n",
    "\n",
    "3) Внедрить систему мониторинга и обновления модели. Это поможет поддерживать высокое качество классификации и адаптироваться к новым условиям, так как со временем нормы языка могут изменяться. То, что сейчас считается токсичным — может таковым не быть через 5 лет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "Рекомендации заказчику хороши.  Но ведь ты сам можешь улучшить метрику, если используешь альтернативу твоему подходу - Берт.  В чём преимущество?!\n",
    "\n",
    "\n",
    "TF-IDF просто считает количество того или иного слова в предложении. Так он переводит текст, который непонятен компьютеру, в числа. Но можно ведь сделать посложнее, и в качестве слова взять вектор, причём так что вектор слово \"мужчина\" и вектор слова \"человек\" были близки - то есть тут уже учитывается внутренняя материя языка. Или например известный пример: создаем такие вектора слов, что если от вектора слова \"король\", отнять Вектор слова \"мужчина\" и добавить Вектор слова \"женщина\", то получится Вектор близкий к вектору слова \"Королева\".  Это можно получить с помощью Word2Vec. Но на самом деле эмбединги (вектора) слов от Берта и подобных ему моделей (Называются модели с Улицы Сезам) еще круче, потому что они ещё и учитывают контекст слова, то есть он работает с целым предложением, и теперь эмбединг одного и того же слова может отличаться в зависимости от того в каком предложении (контексте) он стоит. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Как мы можем использовать Берт?  \n",
    "\n",
    "\n",
    "\n",
    "- Можем его использовать чтобы получить эмбединги и подать их в наши модели как альтернативу векторов от TFIDF/CountVectorizer (чтобы это реализовать можно взять готовый код в тренажёре) - Таким образом мы получаем, (если выбрать верную модель)  метрику за 0,9. \n",
    "    \n",
    "    \n",
    "    \n",
    "- Можно потюнить модель Берта,  можешь взять на основу [статью (там вообще все возможные варианты рассмотрены, причём с использованием разных библиотек)](https://habr.com/ru/articles/704592/) или этот [ролик](https://www.youtube.com/watch?v=Z1J3sTJYIcc&list=PLEwK9wdS5g0qksxWxtE5c2KuFkIfUXe3i&index=14), там прямо можно посмотреть процесс кодирования, и получше разобраться в практической релизации Берта (тут реализация сложнее, метрики я видел за 0,8). Если использовать [Trainer](https://pytorch.org/rl/reference/generated/torchrl.trainers.Trainer.html), будет всё гораздо проще. \n",
    "    \n",
    "    \n",
    "    \n",
    "- И третий вариант еще проще, использовав уже готовые [модели](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html),  которые предсказывают токсичный текст на английском или нет. Использовав эту [схему](https://huggingface.co/unitary/toxic-bert), я видел полученную метрику за 0,9, даже без тюнинга \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарии студентаV1:</b> \n",
    "    \n",
    "Марат, спасибо большое за ревью и различные доп материалы) Этот проект решил всё-таки реализовать без BERT, но в будущем обязательно с ней и ей подобными поработаю</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "Спасибо за работу!  Понял тебя \n",
    " \n",
    "    \n",
    "К сожалению осталось ошибочка -   неправильно применил    TFIDF, в результате произошла утечка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV3</b></font>\n",
    "\n",
    "Спасибо за работу!    \n",
    "\n",
    "    \n",
    " \n",
    "Красного нет, вопросов нет, значит все, пора принимать) Надеюсь мои советы и вопросики были полезны и в копилочку знаний упало что то новое, а проект стал лучше, и симпатичней.\n",
    "\n",
    "  \n",
    "Отличная работа Виктор. Желаю успехов в дальнейшей учебе!\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Виктор, у тебя старательно выполненная работа, все четко, осмысленно. \n",
    "\n",
    "\n",
    "\n",
    "Нет проблем с комментированием кода - всё что ты делаешь понятно\n",
    "\n",
    " \n",
    "\n",
    "Выводы присутствуют, они четкие и подробные.\n",
    "\n",
    "\n",
    "Логика моделирования не нарушена, выборки использованы корректно\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Так как число ошибок небольшое, можешь усложнить проект:\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "- попробуй использовать связку GS+pipeline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- попробуй очень современный и модный сейчас подход с использованием  Берта. Есть несколько вариантов, самый эффективный - это использовать эмбединги (как замена TFIDF) для этого есть уже готовый код в тренажёре (в этом случае разрешается сильно порезать датасет, а если еще и использовать GPU в Colab код можно прогнать за полчаса).\n",
    "\n",
    "\n",
    "\n",
    "- для красивой  визуализации можешь построить облако для токсичных и нетоксичных комментариев\n",
    "\n",
    "\n",
    "\n",
    "- чтобы заглянуть внутрь модели, можешь посмотреть какой из признаков является наиболее важный для логистической регресси (должно получиться слово fuck)   \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "Обязательное к исправлению:\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "\n",
    "- WordNetLemmatizer используем с POS - тег  и применяем к словам а не предложениям\n",
    "\n",
    "\n",
    "\n",
    "- не забываем сделать очистку\n",
    "\n",
    " \n",
    "\n",
    "- нет перебора гиперпараметров (это можно сделать с помощью вручную прописанных циклов либо с помощью GridSearchCV)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "Жду исправлений, для принятия проекта. Если какие то вопросы, то сразу спрашивай ) \n",
    "\n",
    "\n",
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b> \\\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "\n",
    "Если понравилась работа с текстами, то можешь посмотреть очень интересный (но очень-очень сложный) курс лекций: https://github.com/yandexdataschool/nlp_course .\n",
    "\n",
    "Если нравится смотреть и слушать то есть целый курс на Ютубе https://www.youtube.com/watch?v=qDMwIQRQt-M&list=PLEwK9wdS5g0qksxWxtE5c2KuFkIfUXe3i&index=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки\n",
    "<a href=\"#Содержание\">Назад к содержанию</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1752,
    "start_time": "2025-05-23T05:28:03.398Z"
   },
   {
    "duration": 7113,
    "start_time": "2025-05-23T05:28:07.896Z"
   },
   {
    "duration": 971,
    "start_time": "2025-05-23T05:29:27.287Z"
   },
   {
    "duration": 505,
    "start_time": "2025-05-23T05:36:06.643Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-23T05:37:29.665Z"
   },
   {
    "duration": 12,
    "start_time": "2025-05-23T05:37:55.313Z"
   },
   {
    "duration": 29,
    "start_time": "2025-05-23T05:38:13.928Z"
   },
   {
    "duration": 17,
    "start_time": "2025-05-23T05:38:52.671Z"
   },
   {
    "duration": 935,
    "start_time": "2025-05-23T05:39:45.215Z"
   },
   {
    "duration": 18,
    "start_time": "2025-05-23T05:41:28.965Z"
   },
   {
    "duration": 28,
    "start_time": "2025-05-23T05:41:32.773Z"
   },
   {
    "duration": 33,
    "start_time": "2025-05-23T05:44:31.507Z"
   },
   {
    "duration": 234,
    "start_time": "2025-05-23T05:45:27.346Z"
   },
   {
    "duration": 208,
    "start_time": "2025-05-23T05:45:44.970Z"
   },
   {
    "duration": 203,
    "start_time": "2025-05-23T05:46:41.234Z"
   },
   {
    "duration": 191,
    "start_time": "2025-05-23T05:46:52.682Z"
   },
   {
    "duration": 141,
    "start_time": "2025-05-23T05:57:31.801Z"
   },
   {
    "duration": 3149,
    "start_time": "2025-05-23T05:57:50.101Z"
   },
   {
    "duration": 1783,
    "start_time": "2025-05-23T05:57:53.253Z"
   },
   {
    "duration": 147,
    "start_time": "2025-05-23T06:12:23.616Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-23T06:12:27.727Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-23T06:20:52.673Z"
   },
   {
    "duration": 51,
    "start_time": "2025-05-23T06:20:55.224Z"
   },
   {
    "duration": 157,
    "start_time": "2025-05-23T06:23:23.751Z"
   },
   {
    "duration": 14,
    "start_time": "2025-05-23T06:23:46.326Z"
   },
   {
    "duration": 3049,
    "start_time": "2025-05-23T06:23:52.763Z"
   },
   {
    "duration": 1708,
    "start_time": "2025-05-23T06:23:55.815Z"
   },
   {
    "duration": 248,
    "start_time": "2025-05-23T06:23:57.525Z"
   },
   {
    "duration": 909,
    "start_time": "2025-05-23T06:23:57.775Z"
   },
   {
    "duration": 18,
    "start_time": "2025-05-23T06:23:58.685Z"
   },
   {
    "duration": 58,
    "start_time": "2025-05-23T06:23:58.704Z"
   },
   {
    "duration": 230,
    "start_time": "2025-05-23T06:23:58.764Z"
   },
   {
    "duration": 116204,
    "start_time": "2025-05-23T06:23:58.995Z"
   },
   {
    "duration": 14,
    "start_time": "2025-05-23T06:25:55.201Z"
   },
   {
    "duration": 3144,
    "start_time": "2025-05-23T06:28:43.630Z"
   },
   {
    "duration": 1688,
    "start_time": "2025-05-23T06:28:46.776Z"
   },
   {
    "duration": 254,
    "start_time": "2025-05-23T06:28:48.465Z"
   },
   {
    "duration": 947,
    "start_time": "2025-05-23T06:28:48.720Z"
   },
   {
    "duration": 18,
    "start_time": "2025-05-23T06:28:49.677Z"
   },
   {
    "duration": 31,
    "start_time": "2025-05-23T06:28:49.696Z"
   },
   {
    "duration": 239,
    "start_time": "2025-05-23T06:28:49.729Z"
   },
   {
    "duration": 156,
    "start_time": "2025-05-23T06:28:49.970Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-23T06:28:50.127Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-23T06:30:08.025Z"
   },
   {
    "duration": 3040,
    "start_time": "2025-05-23T06:30:16.793Z"
   },
   {
    "duration": 1698,
    "start_time": "2025-05-23T06:30:19.836Z"
   },
   {
    "duration": 248,
    "start_time": "2025-05-23T06:30:21.535Z"
   },
   {
    "duration": 893,
    "start_time": "2025-05-23T06:30:21.785Z"
   },
   {
    "duration": 17,
    "start_time": "2025-05-23T06:30:22.680Z"
   },
   {
    "duration": 61,
    "start_time": "2025-05-23T06:30:22.698Z"
   },
   {
    "duration": 228,
    "start_time": "2025-05-23T06:30:22.760Z"
   },
   {
    "duration": 127837,
    "start_time": "2025-05-23T06:30:22.989Z"
   },
   {
    "duration": 14,
    "start_time": "2025-05-23T06:32:30.828Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-23T06:52:34.520Z"
   },
   {
    "duration": 3401,
    "start_time": "2025-05-23T07:04:34.180Z"
   },
   {
    "duration": 1682,
    "start_time": "2025-05-23T07:04:37.583Z"
   },
   {
    "duration": 180,
    "start_time": "2025-05-23T07:04:39.267Z"
   },
   {
    "duration": 897,
    "start_time": "2025-05-23T07:04:39.449Z"
   },
   {
    "duration": 29,
    "start_time": "2025-05-23T07:04:40.348Z"
   },
   {
    "duration": 36,
    "start_time": "2025-05-23T07:04:40.379Z"
   },
   {
    "duration": 227,
    "start_time": "2025-05-23T07:04:40.417Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-23T07:04:40.646Z"
   },
   {
    "duration": 128059,
    "start_time": "2025-05-23T07:04:40.652Z"
   },
   {
    "duration": 3062,
    "start_time": "2025-05-23T07:07:22.738Z"
   },
   {
    "duration": 2757,
    "start_time": "2025-05-23T07:07:25.802Z"
   },
   {
    "duration": 254,
    "start_time": "2025-05-23T07:07:28.561Z"
   },
   {
    "duration": 919,
    "start_time": "2025-05-23T07:07:28.817Z"
   },
   {
    "duration": 18,
    "start_time": "2025-05-23T07:07:29.737Z"
   },
   {
    "duration": 65,
    "start_time": "2025-05-23T07:07:29.757Z"
   },
   {
    "duration": 224,
    "start_time": "2025-05-23T07:07:29.823Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-23T07:07:30.048Z"
   },
   {
    "duration": 127351,
    "start_time": "2025-05-23T07:07:30.054Z"
   },
   {
    "duration": 48,
    "start_time": "2025-05-23T07:09:53.715Z"
   },
   {
    "duration": 3225,
    "start_time": "2025-05-23T07:21:50.395Z"
   },
   {
    "duration": 2681,
    "start_time": "2025-05-23T07:21:53.622Z"
   },
   {
    "duration": 257,
    "start_time": "2025-05-23T07:21:56.305Z"
   },
   {
    "duration": 926,
    "start_time": "2025-05-23T07:21:56.564Z"
   },
   {
    "duration": 17,
    "start_time": "2025-05-23T07:21:57.492Z"
   },
   {
    "duration": 125,
    "start_time": "2025-05-23T07:21:57.511Z"
   },
   {
    "duration": 241,
    "start_time": "2025-05-23T07:21:57.638Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-23T07:21:57.881Z"
   },
   {
    "duration": 126894,
    "start_time": "2025-05-23T07:21:57.887Z"
   },
   {
    "duration": 5013,
    "start_time": "2025-05-23T07:24:04.783Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-23T08:14:28.044Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-23T08:21:55.872Z"
   },
   {
    "duration": 38,
    "start_time": "2025-05-23T08:22:15.503Z"
   },
   {
    "duration": 3,
    "start_time": "2025-05-23T08:22:49.678Z"
   },
   {
    "duration": 3080,
    "start_time": "2025-05-23T08:37:54.941Z"
   },
   {
    "duration": 1682,
    "start_time": "2025-05-23T08:37:58.023Z"
   },
   {
    "duration": 172,
    "start_time": "2025-05-23T08:37:59.706Z"
   },
   {
    "duration": 911,
    "start_time": "2025-05-23T08:37:59.880Z"
   },
   {
    "duration": 17,
    "start_time": "2025-05-23T08:38:00.793Z"
   },
   {
    "duration": 160,
    "start_time": "2025-05-23T08:38:00.812Z"
   },
   {
    "duration": 254,
    "start_time": "2025-05-23T08:38:00.973Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-23T08:38:01.229Z"
   },
   {
    "duration": 127444,
    "start_time": "2025-05-23T08:38:01.235Z"
   },
   {
    "duration": 5063,
    "start_time": "2025-05-23T08:40:08.681Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-23T08:40:13.746Z"
   },
   {
    "duration": 99,
    "start_time": "2025-05-23T08:40:13.751Z"
   },
   {
    "duration": 3,
    "start_time": "2025-05-23T08:40:13.852Z"
   },
   {
    "duration": 7399,
    "start_time": "2025-05-25T10:04:31.990Z"
   },
   {
    "duration": 1943,
    "start_time": "2025-05-25T10:04:39.391Z"
   },
   {
    "duration": 416,
    "start_time": "2025-05-25T10:04:41.337Z"
   },
   {
    "duration": 988,
    "start_time": "2025-05-25T10:04:41.755Z"
   },
   {
    "duration": 32,
    "start_time": "2025-05-25T10:04:42.745Z"
   },
   {
    "duration": 37,
    "start_time": "2025-05-25T10:04:42.780Z"
   },
   {
    "duration": 283,
    "start_time": "2025-05-25T10:04:42.819Z"
   },
   {
    "duration": 7,
    "start_time": "2025-05-25T10:04:43.104Z"
   },
   {
    "duration": 63,
    "start_time": "2025-05-25T10:04:43.113Z"
   },
   {
    "duration": 131694,
    "start_time": "2025-05-25T10:05:36.013Z"
   },
   {
    "duration": 4959,
    "start_time": "2025-05-25T10:07:47.710Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-25T10:07:52.675Z"
   },
   {
    "duration": 60,
    "start_time": "2025-05-25T10:07:52.681Z"
   },
   {
    "duration": 3119,
    "start_time": "2025-05-25T10:22:54.458Z"
   },
   {
    "duration": 1690,
    "start_time": "2025-05-25T10:22:57.580Z"
   },
   {
    "duration": 179,
    "start_time": "2025-05-25T10:22:59.272Z"
   },
   {
    "duration": 924,
    "start_time": "2025-05-25T10:22:59.453Z"
   },
   {
    "duration": 18,
    "start_time": "2025-05-25T10:23:00.380Z"
   },
   {
    "duration": 34,
    "start_time": "2025-05-25T10:23:00.400Z"
   },
   {
    "duration": 256,
    "start_time": "2025-05-25T10:23:00.436Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-25T10:23:00.693Z"
   },
   {
    "duration": 98,
    "start_time": "2025-05-25T10:23:00.699Z"
   },
   {
    "duration": 129379,
    "start_time": "2025-05-25T10:23:00.799Z"
   },
   {
    "duration": 5338,
    "start_time": "2025-05-25T10:25:10.180Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-25T10:25:15.519Z"
   },
   {
    "duration": 60,
    "start_time": "2025-05-25T10:25:15.524Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-25T10:25:15.587Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-25T10:26:26.326Z"
   },
   {
    "duration": 3052,
    "start_time": "2025-05-25T10:42:10.628Z"
   },
   {
    "duration": 1692,
    "start_time": "2025-05-25T10:42:13.684Z"
   },
   {
    "duration": 181,
    "start_time": "2025-05-25T10:42:15.378Z"
   },
   {
    "duration": 947,
    "start_time": "2025-05-25T10:42:15.560Z"
   },
   {
    "duration": 29,
    "start_time": "2025-05-25T10:42:16.509Z"
   },
   {
    "duration": 46,
    "start_time": "2025-05-25T10:42:16.540Z"
   },
   {
    "duration": 257,
    "start_time": "2025-05-25T10:42:16.588Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-25T10:42:16.847Z"
   },
   {
    "duration": 53,
    "start_time": "2025-05-25T10:42:16.853Z"
   },
   {
    "duration": 128697,
    "start_time": "2025-05-25T10:42:16.908Z"
   },
   {
    "duration": 5331,
    "start_time": "2025-05-25T10:44:25.608Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-25T10:44:30.941Z"
   },
   {
    "duration": 66,
    "start_time": "2025-05-25T10:44:30.947Z"
   },
   {
    "duration": 40,
    "start_time": "2025-05-25T10:44:31.016Z"
   },
   {
    "duration": 116532,
    "start_time": "2025-05-25T10:44:31.058Z"
   },
   {
    "duration": 142621,
    "start_time": "2025-05-25T11:03:10.593Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-25T11:22:26.012Z"
   },
   {
    "duration": 467767,
    "start_time": "2025-05-25T11:22:32.374Z"
   },
   {
    "duration": 186,
    "start_time": "2025-05-25T11:30:20.143Z"
   },
   {
    "duration": 16,
    "start_time": "2025-05-25T11:30:59.549Z"
   },
   {
    "duration": 16,
    "start_time": "2025-05-25T11:31:04.101Z"
   },
   {
    "duration": 22,
    "start_time": "2025-05-25T11:31:08.974Z"
   },
   {
    "duration": 16,
    "start_time": "2025-05-25T11:35:18.418Z"
   },
   {
    "duration": 216,
    "start_time": "2025-05-25T11:35:27.234Z"
   },
   {
    "duration": 160,
    "start_time": "2025-05-25T11:35:35.891Z"
   },
   {
    "duration": 3252,
    "start_time": "2025-05-25T11:44:29.863Z"
   },
   {
    "duration": 1612,
    "start_time": "2025-05-25T11:44:33.118Z"
   },
   {
    "duration": 237,
    "start_time": "2025-05-25T11:44:34.733Z"
   },
   {
    "duration": 1028,
    "start_time": "2025-05-25T11:44:34.972Z"
   },
   {
    "duration": 18,
    "start_time": "2025-05-25T11:44:36.002Z"
   },
   {
    "duration": 31,
    "start_time": "2025-05-25T11:44:36.021Z"
   },
   {
    "duration": 261,
    "start_time": "2025-05-25T11:44:36.054Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-25T11:44:36.317Z"
   },
   {
    "duration": 35,
    "start_time": "2025-05-25T11:44:36.323Z"
   },
   {
    "duration": 276,
    "start_time": "2025-05-25T11:44:36.377Z"
   },
   {
    "duration": 135484,
    "start_time": "2025-05-25T11:44:36.655Z"
   },
   {
    "duration": 5584,
    "start_time": "2025-05-25T11:46:52.141Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-25T11:46:57.727Z"
   },
   {
    "duration": 117,
    "start_time": "2025-05-25T11:46:57.734Z"
   },
   {
    "duration": 91,
    "start_time": "2025-05-25T11:46:57.853Z"
   },
   {
    "duration": 429538,
    "start_time": "2025-05-25T11:46:57.945Z"
   },
   {
    "duration": 15,
    "start_time": "2025-05-25T11:54:07.485Z"
   },
   {
    "duration": 3120,
    "start_time": "2025-05-25T12:10:05.872Z"
   },
   {
    "duration": 1495,
    "start_time": "2025-05-25T12:10:08.994Z"
   },
   {
    "duration": 174,
    "start_time": "2025-05-25T12:10:10.491Z"
   },
   {
    "duration": 1013,
    "start_time": "2025-05-25T12:10:10.668Z"
   },
   {
    "duration": 20,
    "start_time": "2025-05-25T12:10:11.684Z"
   },
   {
    "duration": 32,
    "start_time": "2025-05-25T12:10:11.706Z"
   },
   {
    "duration": 256,
    "start_time": "2025-05-25T12:10:11.740Z"
   },
   {
    "duration": 8,
    "start_time": "2025-05-25T12:10:12.000Z"
   },
   {
    "duration": 90,
    "start_time": "2025-05-25T12:10:12.010Z"
   },
   {
    "duration": 251,
    "start_time": "2025-05-25T12:10:12.102Z"
   },
   {
    "duration": 130788,
    "start_time": "2025-05-25T12:10:12.355Z"
   },
   {
    "duration": 5227,
    "start_time": "2025-05-25T12:12:23.145Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-25T12:12:28.377Z"
   },
   {
    "duration": 113,
    "start_time": "2025-05-25T12:12:28.383Z"
   },
   {
    "duration": 84,
    "start_time": "2025-05-25T12:12:28.498Z"
   },
   {
    "duration": 641229,
    "start_time": "2025-05-25T12:12:28.584Z"
   },
   {
    "duration": 20,
    "start_time": "2025-05-25T12:23:09.815Z"
   },
   {
    "duration": 540141,
    "start_time": "2025-05-25T12:24:47.903Z"
   },
   {
    "duration": 34,
    "start_time": "2025-05-25T12:33:48.046Z"
   },
   {
    "duration": 7275,
    "start_time": "2025-05-26T04:44:59.826Z"
   },
   {
    "duration": 1688,
    "start_time": "2025-05-26T04:45:07.103Z"
   },
   {
    "duration": 467,
    "start_time": "2025-05-26T04:45:08.793Z"
   },
   {
    "duration": 904,
    "start_time": "2025-05-26T04:45:09.261Z"
   },
   {
    "duration": 16,
    "start_time": "2025-05-26T04:45:10.167Z"
   },
   {
    "duration": 89,
    "start_time": "2025-05-26T04:45:10.185Z"
   },
   {
    "duration": 224,
    "start_time": "2025-05-26T04:45:10.276Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-26T04:45:10.502Z"
   },
   {
    "duration": 43,
    "start_time": "2025-05-26T04:45:10.508Z"
   },
   {
    "duration": 245,
    "start_time": "2025-05-26T04:45:10.553Z"
   },
   {
    "duration": 124811,
    "start_time": "2025-05-26T04:45:10.800Z"
   },
   {
    "duration": 5016,
    "start_time": "2025-05-26T04:47:15.613Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-26T04:47:20.631Z"
   },
   {
    "duration": 130,
    "start_time": "2025-05-26T04:47:20.638Z"
   },
   {
    "duration": 71,
    "start_time": "2025-05-26T04:47:20.769Z"
   },
   {
    "duration": 227654,
    "start_time": "2025-05-26T04:47:20.842Z"
   },
   {
    "duration": 21,
    "start_time": "2025-05-26T04:51:08.497Z"
   },
   {
    "duration": 7541,
    "start_time": "2025-05-27T09:14:10.230Z"
   },
   {
    "duration": 4736,
    "start_time": "2025-05-27T09:14:17.773Z"
   },
   {
    "duration": 921,
    "start_time": "2025-05-27T09:14:22.511Z"
   },
   {
    "duration": 16,
    "start_time": "2025-05-27T09:14:23.435Z"
   },
   {
    "duration": 46,
    "start_time": "2025-05-27T09:14:23.453Z"
   },
   {
    "duration": 226,
    "start_time": "2025-05-27T09:14:25.241Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-27T09:14:27.105Z"
   },
   {
    "duration": 31,
    "start_time": "2025-05-27T09:14:28.521Z"
   },
   {
    "duration": 162,
    "start_time": "2025-05-27T09:14:30.547Z"
   },
   {
    "duration": 2858957,
    "start_time": "2025-05-27T09:22:38.060Z"
   },
   {
    "duration": 380,
    "start_time": "2025-05-27T10:10:17.021Z"
   },
   {
    "duration": 3542,
    "start_time": "2025-05-27T10:10:34.879Z"
   },
   {
    "duration": 1773,
    "start_time": "2025-05-27T10:11:00.527Z"
   },
   {
    "duration": 10,
    "start_time": "2025-05-27T10:13:03.829Z"
   },
   {
    "duration": 6856,
    "start_time": "2025-05-27T10:16:44.434Z"
   },
   {
    "duration": 38,
    "start_time": "2025-05-27T10:16:51.293Z"
   },
   {
    "duration": 21,
    "start_time": "2025-05-27T10:17:07.817Z"
   },
   {
    "duration": 19,
    "start_time": "2025-05-27T10:17:10.938Z"
   },
   {
    "duration": 9241,
    "start_time": "2025-05-27T10:18:00.444Z"
   },
   {
    "duration": 36,
    "start_time": "2025-05-27T10:18:09.688Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-27T10:19:02.119Z"
   },
   {
    "duration": 8747,
    "start_time": "2025-05-27T10:19:32.238Z"
   },
   {
    "duration": 4396,
    "start_time": "2025-05-27T10:19:40.988Z"
   },
   {
    "duration": 972,
    "start_time": "2025-05-27T10:19:45.386Z"
   },
   {
    "duration": 17,
    "start_time": "2025-05-27T10:19:46.360Z"
   },
   {
    "duration": 46,
    "start_time": "2025-05-27T10:19:46.379Z"
   },
   {
    "duration": 241,
    "start_time": "2025-05-27T10:19:46.427Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-27T10:19:46.670Z"
   },
   {
    "duration": 96,
    "start_time": "2025-05-27T10:19:46.676Z"
   },
   {
    "duration": 163,
    "start_time": "2025-05-27T10:19:46.774Z"
   },
   {
    "duration": 2140,
    "start_time": "2025-05-27T10:19:46.940Z"
   },
   {
    "duration": 8506,
    "start_time": "2025-05-27T10:34:22.299Z"
   },
   {
    "duration": 4688,
    "start_time": "2025-05-27T10:34:30.807Z"
   },
   {
    "duration": 987,
    "start_time": "2025-05-27T10:34:35.497Z"
   },
   {
    "duration": 28,
    "start_time": "2025-05-27T10:34:36.486Z"
   },
   {
    "duration": 30,
    "start_time": "2025-05-27T10:34:36.515Z"
   },
   {
    "duration": 268,
    "start_time": "2025-05-27T10:34:36.547Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-27T10:34:36.818Z"
   },
   {
    "duration": 63,
    "start_time": "2025-05-27T10:34:36.826Z"
   },
   {
    "duration": 181,
    "start_time": "2025-05-27T10:34:36.891Z"
   },
   {
    "duration": 364,
    "start_time": "2025-05-27T10:34:37.076Z"
   },
   {
    "duration": 152933,
    "start_time": "2025-05-27T10:35:08.244Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-27T10:47:14.210Z"
   },
   {
    "duration": 8485,
    "start_time": "2025-05-27T10:51:50.846Z"
   },
   {
    "duration": 4439,
    "start_time": "2025-05-27T10:51:59.334Z"
   },
   {
    "duration": 958,
    "start_time": "2025-05-27T10:52:03.775Z"
   },
   {
    "duration": 18,
    "start_time": "2025-05-27T10:52:04.735Z"
   },
   {
    "duration": 141,
    "start_time": "2025-05-27T10:52:04.755Z"
   },
   {
    "duration": 254,
    "start_time": "2025-05-27T10:52:04.898Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-27T10:52:05.154Z"
   },
   {
    "duration": 55,
    "start_time": "2025-05-27T10:52:05.160Z"
   },
   {
    "duration": 187,
    "start_time": "2025-05-27T10:52:05.217Z"
   },
   {
    "duration": 152151,
    "start_time": "2025-05-27T10:52:05.406Z"
   },
   {
    "duration": 130,
    "start_time": "2025-05-27T10:57:27.100Z"
   },
   {
    "duration": 485,
    "start_time": "2025-05-27T10:58:35.810Z"
   },
   {
    "duration": 195,
    "start_time": "2025-05-27T10:58:44.298Z"
   },
   {
    "duration": 294,
    "start_time": "2025-05-27T10:59:16.321Z"
   },
   {
    "duration": 279,
    "start_time": "2025-05-27T11:02:41.855Z"
   },
   {
    "duration": 388,
    "start_time": "2025-05-27T11:06:10.084Z"
   },
   {
    "duration": 2219,
    "start_time": "2025-05-27T11:10:11.921Z"
   },
   {
    "duration": 24,
    "start_time": "2025-05-27T11:11:45.639Z"
   },
   {
    "duration": 31051,
    "start_time": "2025-05-27T11:15:23.165Z"
   },
   {
    "duration": 13760,
    "start_time": "2025-05-27T11:20:00.809Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-27T11:20:14.572Z"
   },
   {
    "duration": 31231,
    "start_time": "2025-05-27T11:20:24.105Z"
   },
   {
    "duration": 159,
    "start_time": "2025-05-27T11:23:51.975Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-27T11:24:23.175Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-27T11:24:42.854Z"
   },
   {
    "duration": 60,
    "start_time": "2025-05-27T11:26:54.437Z"
   },
   {
    "duration": 31036,
    "start_time": "2025-05-27T11:27:05.596Z"
   },
   {
    "duration": 13019,
    "start_time": "2025-05-27T11:29:38.394Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-27T11:29:51.416Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-27T11:30:00.977Z"
   },
   {
    "duration": 31152,
    "start_time": "2025-05-27T11:30:04.658Z"
   },
   {
    "duration": 13660,
    "start_time": "2025-05-27T11:31:35.609Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-27T11:31:49.272Z"
   },
   {
    "duration": 30926,
    "start_time": "2025-05-27T11:32:05.152Z"
   },
   {
    "duration": 12690,
    "start_time": "2025-05-27T11:41:47.703Z"
   },
   {
    "duration": 4638,
    "start_time": "2025-05-27T11:42:00.396Z"
   },
   {
    "duration": 983,
    "start_time": "2025-05-27T11:42:05.036Z"
   },
   {
    "duration": 19,
    "start_time": "2025-05-27T11:42:06.021Z"
   },
   {
    "duration": 67,
    "start_time": "2025-05-27T11:42:06.042Z"
   },
   {
    "duration": 363,
    "start_time": "2025-05-27T11:42:06.111Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-27T11:42:06.475Z"
   },
   {
    "duration": 91,
    "start_time": "2025-05-27T11:42:06.483Z"
   },
   {
    "duration": 183,
    "start_time": "2025-05-27T11:42:06.575Z"
   },
   {
    "duration": 393,
    "start_time": "2025-05-27T11:42:06.760Z"
   },
   {
    "duration": 2379,
    "start_time": "2025-05-27T11:42:07.155Z"
   },
   {
    "duration": 4780,
    "start_time": "2025-05-27T11:42:09.535Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-27T11:42:14.317Z"
   },
   {
    "duration": 103,
    "start_time": "2025-05-27T11:42:14.322Z"
   },
   {
    "duration": 12523,
    "start_time": "2025-05-27T11:48:33.955Z"
   },
   {
    "duration": 4514,
    "start_time": "2025-05-27T11:48:46.481Z"
   },
   {
    "duration": 971,
    "start_time": "2025-05-27T11:48:50.997Z"
   },
   {
    "duration": 19,
    "start_time": "2025-05-27T11:48:51.969Z"
   },
   {
    "duration": 39,
    "start_time": "2025-05-27T11:48:51.990Z"
   },
   {
    "duration": 257,
    "start_time": "2025-05-27T11:48:52.031Z"
   },
   {
    "duration": 17,
    "start_time": "2025-05-27T11:48:52.291Z"
   },
   {
    "duration": 59,
    "start_time": "2025-05-27T11:48:52.310Z"
   },
   {
    "duration": 159,
    "start_time": "2025-05-27T11:48:52.371Z"
   },
   {
    "duration": 377,
    "start_time": "2025-05-27T11:48:52.532Z"
   },
   {
    "duration": 2274,
    "start_time": "2025-05-27T11:48:52.912Z"
   },
   {
    "duration": 4858,
    "start_time": "2025-05-27T11:48:55.187Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-27T11:49:00.047Z"
   },
   {
    "duration": 133,
    "start_time": "2025-05-27T11:49:00.053Z"
   },
   {
    "duration": 348,
    "start_time": "2025-05-27T11:49:00.188Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-27T11:49:00.537Z"
   },
   {
    "duration": 12628,
    "start_time": "2025-05-27T11:55:07.981Z"
   },
   {
    "duration": 4672,
    "start_time": "2025-05-27T11:55:20.612Z"
   },
   {
    "duration": 975,
    "start_time": "2025-05-27T11:55:25.285Z"
   },
   {
    "duration": 19,
    "start_time": "2025-05-27T11:55:26.262Z"
   },
   {
    "duration": 47,
    "start_time": "2025-05-27T11:55:26.283Z"
   },
   {
    "duration": 255,
    "start_time": "2025-05-27T11:55:26.332Z"
   },
   {
    "duration": 16,
    "start_time": "2025-05-27T11:55:26.589Z"
   },
   {
    "duration": 34,
    "start_time": "2025-05-27T11:55:26.607Z"
   },
   {
    "duration": 164,
    "start_time": "2025-05-27T11:55:26.643Z"
   },
   {
    "duration": 364,
    "start_time": "2025-05-27T11:55:26.808Z"
   },
   {
    "duration": 2691,
    "start_time": "2025-05-27T11:55:27.174Z"
   },
   {
    "duration": 4976,
    "start_time": "2025-05-27T11:55:29.866Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-27T11:55:34.844Z"
   },
   {
    "duration": 118,
    "start_time": "2025-05-27T11:55:34.852Z"
   },
   {
    "duration": 16394,
    "start_time": "2025-05-27T11:55:34.971Z"
   },
   {
    "duration": 12201,
    "start_time": "2025-05-27T11:57:25.544Z"
   },
   {
    "duration": 4435,
    "start_time": "2025-05-27T11:57:37.747Z"
   },
   {
    "duration": 971,
    "start_time": "2025-05-27T11:57:42.183Z"
   },
   {
    "duration": 18,
    "start_time": "2025-05-27T11:57:43.156Z"
   },
   {
    "duration": 51,
    "start_time": "2025-05-27T11:57:43.178Z"
   },
   {
    "duration": 246,
    "start_time": "2025-05-27T11:57:43.231Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-27T11:57:43.479Z"
   },
   {
    "duration": 50,
    "start_time": "2025-05-27T11:57:43.485Z"
   },
   {
    "duration": 163,
    "start_time": "2025-05-27T11:57:43.537Z"
   },
   {
    "duration": 391,
    "start_time": "2025-05-27T11:57:43.705Z"
   },
   {
    "duration": 2666,
    "start_time": "2025-05-27T11:57:44.106Z"
   },
   {
    "duration": 4854,
    "start_time": "2025-05-27T11:57:46.774Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-27T11:57:51.630Z"
   },
   {
    "duration": 106,
    "start_time": "2025-05-27T11:57:51.636Z"
   },
   {
    "duration": 82,
    "start_time": "2025-05-27T11:57:51.744Z"
   },
   {
    "duration": 1664777,
    "start_time": "2025-05-27T11:57:51.828Z"
   },
   {
    "duration": 357,
    "start_time": "2025-05-27T12:29:15.214Z"
   },
   {
    "duration": 19,
    "start_time": "2025-05-27T12:29:27.907Z"
   },
   {
    "duration": 19,
    "start_time": "2025-05-27T12:35:12.293Z"
   },
   {
    "duration": 34,
    "start_time": "2025-05-27T12:39:23.950Z"
   },
   {
    "duration": 12307,
    "start_time": "2025-05-27T12:39:44.946Z"
   },
   {
    "duration": 4379,
    "start_time": "2025-05-27T12:39:57.255Z"
   },
   {
    "duration": 959,
    "start_time": "2025-05-27T12:40:01.636Z"
   },
   {
    "duration": 27,
    "start_time": "2025-05-27T12:40:02.597Z"
   },
   {
    "duration": 121,
    "start_time": "2025-05-27T12:40:02.626Z"
   },
   {
    "duration": 337,
    "start_time": "2025-05-27T12:40:02.749Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-27T12:40:03.087Z"
   },
   {
    "duration": 143,
    "start_time": "2025-05-27T12:40:03.093Z"
   },
   {
    "duration": 191,
    "start_time": "2025-05-27T12:40:03.238Z"
   },
   {
    "duration": 352,
    "start_time": "2025-05-27T12:40:03.431Z"
   },
   {
    "duration": 2543,
    "start_time": "2025-05-27T12:40:03.805Z"
   },
   {
    "duration": 4845,
    "start_time": "2025-05-27T12:40:06.350Z"
   },
   {
    "duration": 9,
    "start_time": "2025-05-27T12:40:11.197Z"
   },
   {
    "duration": 144,
    "start_time": "2025-05-27T12:40:11.208Z"
   },
   {
    "duration": 74,
    "start_time": "2025-05-27T12:40:11.354Z"
   },
   {
    "duration": 346,
    "start_time": "2025-05-27T12:40:11.430Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-27T12:40:11.778Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-27T12:40:11.779Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-27T12:41:04.858Z"
   },
   {
    "duration": 24,
    "start_time": "2025-05-27T12:41:19.187Z"
   },
   {
    "duration": 158075,
    "start_time": "2025-05-27T12:44:59.696Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-27T12:47:37.772Z"
   },
   {
    "duration": 156164,
    "start_time": "2025-05-27T12:47:54.807Z"
   },
   {
    "duration": 24,
    "start_time": "2025-05-27T12:56:52.626Z"
   },
   {
    "duration": 12365,
    "start_time": "2025-05-27T12:57:06.509Z"
   },
   {
    "duration": 4501,
    "start_time": "2025-05-27T12:57:18.877Z"
   },
   {
    "duration": 981,
    "start_time": "2025-05-27T12:57:23.380Z"
   },
   {
    "duration": 20,
    "start_time": "2025-05-27T12:57:24.362Z"
   },
   {
    "duration": 65,
    "start_time": "2025-05-27T12:57:24.385Z"
   },
   {
    "duration": 305,
    "start_time": "2025-05-27T12:57:24.451Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-27T12:57:24.757Z"
   },
   {
    "duration": 87,
    "start_time": "2025-05-27T12:57:24.764Z"
   },
   {
    "duration": 187,
    "start_time": "2025-05-27T12:57:24.852Z"
   },
   {
    "duration": 419,
    "start_time": "2025-05-27T12:57:25.041Z"
   },
   {
    "duration": 2334,
    "start_time": "2025-05-27T12:57:25.462Z"
   },
   {
    "duration": 4888,
    "start_time": "2025-05-27T12:57:27.805Z"
   },
   {
    "duration": 11,
    "start_time": "2025-05-27T12:57:32.695Z"
   },
   {
    "duration": 88,
    "start_time": "2025-05-27T12:57:32.709Z"
   },
   {
    "duration": 72,
    "start_time": "2025-05-27T12:57:32.806Z"
   },
   {
    "duration": 375,
    "start_time": "2025-05-27T12:57:32.880Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-27T12:57:33.257Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-27T12:57:33.258Z"
   },
   {
    "duration": 361021,
    "start_time": "2025-05-27T12:59:01.134Z"
   },
   {
    "duration": 16,
    "start_time": "2025-05-27T13:05:02.156Z"
   },
   {
    "duration": 18994,
    "start_time": "2025-05-28T11:42:26.588Z"
   },
   {
    "duration": 4552,
    "start_time": "2025-05-28T11:42:45.584Z"
   },
   {
    "duration": 916,
    "start_time": "2025-05-28T11:42:50.138Z"
   },
   {
    "duration": 20,
    "start_time": "2025-05-28T11:42:51.057Z"
   },
   {
    "duration": 42,
    "start_time": "2025-05-28T11:42:51.078Z"
   },
   {
    "duration": 240,
    "start_time": "2025-05-28T11:42:51.121Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-28T11:42:51.362Z"
   },
   {
    "duration": 49,
    "start_time": "2025-05-28T11:42:51.368Z"
   },
   {
    "duration": 168,
    "start_time": "2025-05-28T11:42:51.419Z"
   },
   {
    "duration": 439,
    "start_time": "2025-05-28T11:42:51.590Z"
   },
   {
    "duration": 2152,
    "start_time": "2025-05-28T11:42:52.031Z"
   },
   {
    "duration": 4809,
    "start_time": "2025-05-28T11:42:54.185Z"
   },
   {
    "duration": 10,
    "start_time": "2025-05-28T11:42:58.996Z"
   },
   {
    "duration": 98,
    "start_time": "2025-05-28T11:42:59.008Z"
   },
   {
    "duration": 73,
    "start_time": "2025-05-28T11:42:59.108Z"
   },
   {
    "duration": 356784,
    "start_time": "2025-05-28T11:42:59.183Z"
   },
   {
    "duration": 14,
    "start_time": "2025-05-28T11:48:55.969Z"
   },
   {
    "duration": 35,
    "start_time": "2025-05-28T11:48:55.985Z"
   },
   {
    "duration": 12276,
    "start_time": "2025-05-28T12:08:34.331Z"
   },
   {
    "duration": 4680,
    "start_time": "2025-05-28T12:08:46.609Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:08:51.291Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:08:51.293Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:08:51.295Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:08:51.296Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:08:51.305Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:08:51.307Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:08:51.309Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:08:51.311Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:08:51.312Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:08:51.314Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:08:51.315Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:08:51.317Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:08:51.318Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:08:51.320Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:08:51.321Z"
   },
   {
    "duration": 12270,
    "start_time": "2025-05-28T12:11:37.058Z"
   },
   {
    "duration": 4374,
    "start_time": "2025-05-28T12:11:49.331Z"
   },
   {
    "duration": 965,
    "start_time": "2025-05-28T12:11:53.706Z"
   },
   {
    "duration": 19,
    "start_time": "2025-05-28T12:11:54.673Z"
   },
   {
    "duration": 80,
    "start_time": "2025-05-28T12:11:54.705Z"
   },
   {
    "duration": 255,
    "start_time": "2025-05-28T12:11:54.787Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-28T12:11:55.045Z"
   },
   {
    "duration": 53,
    "start_time": "2025-05-28T12:11:55.052Z"
   },
   {
    "duration": 249,
    "start_time": "2025-05-28T12:11:55.107Z"
   },
   {
    "duration": 420,
    "start_time": "2025-05-28T12:11:55.359Z"
   },
   {
    "duration": 2351,
    "start_time": "2025-05-28T12:11:55.781Z"
   },
   {
    "duration": 4960,
    "start_time": "2025-05-28T12:11:58.134Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-28T12:12:03.095Z"
   },
   {
    "duration": 161,
    "start_time": "2025-05-28T12:12:03.110Z"
   },
   {
    "duration": 1189642,
    "start_time": "2025-05-28T12:12:03.273Z"
   },
   {
    "duration": 367,
    "start_time": "2025-05-28T12:31:52.917Z"
   },
   {
    "duration": 0,
    "start_time": "2025-05-28T12:31:53.285Z"
   },
   {
    "duration": 111,
    "start_time": "2025-05-28T12:49:01.608Z"
   },
   {
    "duration": 16,
    "start_time": "2025-05-28T12:49:12.440Z"
   },
   {
    "duration": 16,
    "start_time": "2025-05-28T12:54:58.891Z"
   },
   {
    "duration": 15,
    "start_time": "2025-05-28T12:55:15.420Z"
   },
   {
    "duration": 17415,
    "start_time": "2025-05-29T06:28:49.681Z"
   },
   {
    "duration": 4412,
    "start_time": "2025-05-29T06:29:07.099Z"
   },
   {
    "duration": 910,
    "start_time": "2025-05-29T06:29:11.513Z"
   },
   {
    "duration": 21,
    "start_time": "2025-05-29T06:29:12.425Z"
   },
   {
    "duration": 115,
    "start_time": "2025-05-29T06:29:12.448Z"
   },
   {
    "duration": 231,
    "start_time": "2025-05-29T06:29:12.565Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-29T06:29:12.797Z"
   },
   {
    "duration": 46,
    "start_time": "2025-05-29T06:29:12.803Z"
   },
   {
    "duration": 147,
    "start_time": "2025-05-29T06:29:12.850Z"
   },
   {
    "duration": 443,
    "start_time": "2025-05-29T06:29:12.998Z"
   },
   {
    "duration": 2213,
    "start_time": "2025-05-29T06:29:13.443Z"
   },
   {
    "duration": 324,
    "start_time": "2025-05-29T06:29:15.657Z"
   },
   {
    "duration": 85,
    "start_time": "2025-05-29T06:30:01.022Z"
   },
   {
    "duration": 10,
    "start_time": "2025-05-29T06:30:20.119Z"
   },
   {
    "duration": 13,
    "start_time": "2025-05-29T06:30:28.157Z"
   },
   {
    "duration": 125,
    "start_time": "2025-05-29T06:33:53.354Z"
   },
   {
    "duration": 10,
    "start_time": "2025-05-29T06:35:08.938Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-29T06:38:01.948Z"
   },
   {
    "duration": 104,
    "start_time": "2025-05-29T06:38:41.939Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-29T06:38:56.438Z"
   },
   {
    "duration": 11218,
    "start_time": "2025-05-29T06:39:38.182Z"
   },
   {
    "duration": 4266,
    "start_time": "2025-05-29T06:39:49.403Z"
   },
   {
    "duration": 888,
    "start_time": "2025-05-29T06:39:53.671Z"
   },
   {
    "duration": 17,
    "start_time": "2025-05-29T06:39:54.561Z"
   },
   {
    "duration": 31,
    "start_time": "2025-05-29T06:39:54.580Z"
   },
   {
    "duration": 234,
    "start_time": "2025-05-29T06:39:54.613Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-29T06:39:54.849Z"
   },
   {
    "duration": 178,
    "start_time": "2025-05-29T06:39:54.855Z"
   },
   {
    "duration": 274,
    "start_time": "2025-05-29T06:39:55.035Z"
   },
   {
    "duration": 370,
    "start_time": "2025-05-29T06:39:55.310Z"
   },
   {
    "duration": 2448,
    "start_time": "2025-05-29T06:39:55.682Z"
   },
   {
    "duration": 85,
    "start_time": "2025-05-29T06:39:58.131Z"
   },
   {
    "duration": 24,
    "start_time": "2025-05-29T06:39:58.218Z"
   },
   {
    "duration": 437,
    "start_time": "2025-05-29T06:39:58.244Z"
   },
   {
    "duration": 78,
    "start_time": "2025-05-29T06:41:49.500Z"
   },
   {
    "duration": 73,
    "start_time": "2025-05-29T06:42:00.828Z"
   },
   {
    "duration": 66,
    "start_time": "2025-05-29T06:42:38.547Z"
   },
   {
    "duration": 69,
    "start_time": "2025-05-29T06:43:00.978Z"
   },
   {
    "duration": 11417,
    "start_time": "2025-05-29T06:46:28.171Z"
   },
   {
    "duration": 64,
    "start_time": "2025-05-29T06:46:54.836Z"
   },
   {
    "duration": 11610,
    "start_time": "2025-05-29T06:47:03.136Z"
   },
   {
    "duration": 4326,
    "start_time": "2025-05-29T06:47:14.752Z"
   },
   {
    "duration": 886,
    "start_time": "2025-05-29T06:47:19.079Z"
   },
   {
    "duration": 17,
    "start_time": "2025-05-29T06:47:19.967Z"
   },
   {
    "duration": 40,
    "start_time": "2025-05-29T06:47:19.986Z"
   },
   {
    "duration": 298,
    "start_time": "2025-05-29T06:47:20.027Z"
   },
   {
    "duration": 24,
    "start_time": "2025-05-29T06:47:20.327Z"
   },
   {
    "duration": 36,
    "start_time": "2025-05-29T06:47:20.352Z"
   },
   {
    "duration": 144,
    "start_time": "2025-05-29T06:47:20.389Z"
   },
   {
    "duration": 387,
    "start_time": "2025-05-29T06:47:20.540Z"
   },
   {
    "duration": 2283,
    "start_time": "2025-05-29T06:47:20.929Z"
   },
   {
    "duration": 93,
    "start_time": "2025-05-29T06:47:23.213Z"
   },
   {
    "duration": 4957,
    "start_time": "2025-05-29T06:47:23.307Z"
   },
   {
    "duration": 446,
    "start_time": "2025-05-29T06:47:45.712Z"
   },
   {
    "duration": 10911,
    "start_time": "2025-05-29T06:48:31.554Z"
   },
   {
    "duration": 4010,
    "start_time": "2025-05-29T06:48:42.467Z"
   },
   {
    "duration": 894,
    "start_time": "2025-05-29T06:48:46.479Z"
   },
   {
    "duration": 20,
    "start_time": "2025-05-29T06:48:47.375Z"
   },
   {
    "duration": 56,
    "start_time": "2025-05-29T06:48:47.397Z"
   },
   {
    "duration": 248,
    "start_time": "2025-05-29T06:48:47.455Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-29T06:48:47.705Z"
   },
   {
    "duration": 63,
    "start_time": "2025-05-29T06:48:47.712Z"
   },
   {
    "duration": 154,
    "start_time": "2025-05-29T06:48:47.777Z"
   },
   {
    "duration": 372,
    "start_time": "2025-05-29T06:48:47.939Z"
   },
   {
    "duration": 2309,
    "start_time": "2025-05-29T06:48:48.313Z"
   },
   {
    "duration": 84,
    "start_time": "2025-05-29T06:48:50.623Z"
   },
   {
    "duration": 4672,
    "start_time": "2025-05-29T06:48:50.709Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-29T06:48:55.383Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-29T06:49:33.878Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-29T06:50:33.565Z"
   },
   {
    "duration": 10945,
    "start_time": "2025-05-29T06:50:42.005Z"
   },
   {
    "duration": 4143,
    "start_time": "2025-05-29T06:50:52.952Z"
   },
   {
    "duration": 877,
    "start_time": "2025-05-29T06:50:57.097Z"
   },
   {
    "duration": 19,
    "start_time": "2025-05-29T06:50:57.977Z"
   },
   {
    "duration": 46,
    "start_time": "2025-05-29T06:50:57.998Z"
   },
   {
    "duration": 285,
    "start_time": "2025-05-29T06:50:58.046Z"
   },
   {
    "duration": 9,
    "start_time": "2025-05-29T06:50:58.333Z"
   },
   {
    "duration": 68,
    "start_time": "2025-05-29T06:50:58.344Z"
   },
   {
    "duration": 134,
    "start_time": "2025-05-29T06:50:58.413Z"
   },
   {
    "duration": 360,
    "start_time": "2025-05-29T06:50:58.550Z"
   },
   {
    "duration": 2065,
    "start_time": "2025-05-29T06:50:58.912Z"
   },
   {
    "duration": 99,
    "start_time": "2025-05-29T06:51:00.980Z"
   },
   {
    "duration": 4495,
    "start_time": "2025-05-29T06:51:01.080Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-29T06:51:05.576Z"
   },
   {
    "duration": 1097389,
    "start_time": "2025-05-29T06:51:05.581Z"
   },
   {
    "duration": 15,
    "start_time": "2025-05-29T07:09:22.971Z"
   },
   {
    "duration": 38,
    "start_time": "2025-05-29T07:09:22.987Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
